{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pakyeon/deep-rl-class-ko/blob/main/notebooks/ko/unit2/unit2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njb_ProuHiOe"
      },
      "source": [
        "# ìœ ë‹› 2: FrozenLake-v1 â›„ ë° Taxi-v3 ğŸš•ë¥¼ ì‚¬ìš©í•œ Q-Learning\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/thumbnail.jpg\" alt=\"Unit 2 Thumbnail\">\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **ì²˜ìŒìœ¼ë¡œ ê°•í™” í•™ìŠµ ì—ì´ì „íŠ¸ë¥¼ ì§ì ‘ ì½”ë”©**í•˜ì—¬ FrozenLake â„ï¸ë¥¼ Q-Learningì„ í†µí•´ í”Œë ˆì´í•˜ê³ , ì´ë¥¼ ì»¤ë®¤ë‹ˆí‹°ì™€ ê³µìœ í•˜ë©° ë‹¤ì–‘í•œ ì„¤ì •ì„ ì‹¤í—˜í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "â¬‡ï¸ ì•„ë˜ëŠ” **ë‹¨ ëª‡ ë¶„ ë§Œì— ì—¬ëŸ¬ë¶„ì´ ì–»ê²Œ ë  ê²°ê³¼ë¬¼ì˜ ì˜ˆì‹œì…ë‹ˆë‹¤.** â¬‡ï¸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRU_vXBrl1Jx"
      },
      "source": [
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/envs.gif\" alt=\"Environments\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPTBOv9HYLZ2"
      },
      "source": [
        "### ğŸ® í™˜ê²½:\n",
        "\n",
        "- [FrozenLake-v1](https://gymnasium.farama.org/environments/toy_text/frozen_lake/)\n",
        "- [Taxi-v3](https://gymnasium.farama.org/environments/toy_text/taxi/)\n",
        "\n",
        "### ğŸ“š RL ë¼ì´ë¸ŒëŸ¬ë¦¬:\n",
        "\n",
        "- Python ë° NumPy  \n",
        "- [Gymnasium](https://gymnasium.farama.org/)\n",
        "\n",
        "ìš°ë¦¬ëŠ” íŠœí† ë¦¬ì–¼ì„ ì§€ì†ì ìœ¼ë¡œ ê°œì„ í•˜ê³  ìˆìœ¼ë‹ˆ, **ì´ ë…¸íŠ¸ë¶ì—ì„œ ë¬¸ì œë¥¼ ë°œê²¬í•˜ì…¨ë‹¤ë©´** [GitHub ì €ì¥ì†Œì— ì´ìŠˆë¥¼ ë“±ë¡í•´ ì£¼ì„¸ìš”](https://github.com/huggingface/deep-rl-class/issues)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i6tjI2tHQ8j"
      },
      "source": [
        "## ì´ ë…¸íŠ¸ë¶ì˜ ëª©í‘œ ğŸ†\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì„ ë§ˆì¹˜ë©´, ì—¬ëŸ¬ë¶„ì€ ë‹¤ìŒì„ í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤:\n",
        "\n",
        "- **Gymnasium** í™˜ê²½ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
        "- Q-Learning ì—ì´ì „íŠ¸ë¥¼ ì²˜ìŒë¶€í„° ì§ì ‘ ì½”ë”©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
        "- **í•™ìŠµì‹œí‚¨ ì—ì´ì „íŠ¸ì™€ ì½”ë“œë¥¼ Hubì— ì—…ë¡œë“œ**í•˜ê³ , ë©‹ì§„ ë¹„ë””ì˜¤ ë¦¬í”Œë ˆì´ì™€ í‰ê°€ ì ìˆ˜ ğŸ”¥ê¹Œì§€ í•¨ê»˜ ê³µìœ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viNzVbVaYvY3"
      },
      "source": [
        "## ì´ ë…¸íŠ¸ë¶ì€ ë”¥ ê°•í™” í•™ìŠµ ê³¼ì •(Deep Reinforcement Learning Course)ì˜ ì¼ë¶€ì…ë‹ˆë‹¤\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/deep-rl-course-illustration.jpg\" alt=\"Deep RL Course illustration\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p5HnEefISCB"
      },
      "source": [
        "ì´ ë¬´ë£Œ ê°•ì¢Œì—ì„œëŠ” ë‹¤ìŒì„ ë°°ìš°ê²Œ ë©ë‹ˆë‹¤:\n",
        "\n",
        "- ğŸ“– **ì´ë¡ ê³¼ ì‹¤ìŠµ**ì„ í†µí•´ ë”¥ ê°•í™” í•™ìŠµ(Deep Reinforcement Learning)ì„ í•™ìŠµí•©ë‹ˆë‹¤.  \n",
        "- ğŸ§‘â€ğŸ’» Stable Baselines3, RL Baselines3 Zoo, CleanRL, Sample Factory 2.0 ê°™ì€ **ìœ ëª…í•œ ë”¥ RL ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•**ì„ ë°°ì›ë‹ˆë‹¤.  \n",
        "- ğŸ¤– **ë‹¤ì–‘í•œ ë…íŠ¹í•œ í™˜ê²½ì—ì„œ ì—ì´ì „íŠ¸ë¥¼ í›ˆë ¨**ì‹œí‚µë‹ˆë‹¤.\n",
        "\n",
        "ê·¸ë¦¬ê³  ê·¸ ì™¸ ë” ë§ì€ ë‚´ìš©ì„ ë°°ìš¸ ìˆ˜ ìˆì–´ìš”. ğŸ“š ì „ì²´ ì»¤ë¦¬í˜ëŸ¼ì€ ğŸ‘‰ [ì—¬ê¸°ì—ì„œ í™•ì¸í•˜ì„¸ìš”](https://simoninithomas.github.io/deep-rl-course)\n",
        "\n",
        "ë˜í•œ **[ì´ê³³ì„ í´ë¦­í•´ ì½”ìŠ¤ì— ë“±ë¡í•˜ì„¸ìš”](http://eepurl.com/ic5ZUD)**  \n",
        "(ë“±ë¡ ì‹œ ì´ë©”ì¼ì„ ìˆ˜ì§‘í•˜ëŠ” ì´ìœ ëŠ” ê° ìœ ë‹›ì´ ê³µê°œë  ë•Œ ë§í¬ë¥¼ ë³´ë‚´ë“œë¦¬ê³ , ì±Œë¦°ì§€ë‚˜ ì—…ë°ì´íŠ¸ ì •ë³´ë¥¼ ì „ë‹¬í•´ë“œë¦¬ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.)\n",
        "\n",
        "ì»¤ë®¤ë‹ˆí‹°ì™€ êµë¥˜í•˜ê³  ì €í¬ì™€ ì†Œí†µí•˜ë ¤ë©´ ë””ìŠ¤ì½”ë“œ ì„œë²„ì— ì°¸ì—¬í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì¢‹ìŠµë‹ˆë‹¤ ğŸ‘‰ğŸ» https://discord.gg/ydHrjt3WP5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-mo_6rXIjRi"
      },
      "source": [
        "## ì‚¬ì „ ì¤€ë¹„ ì‚¬í•­ ğŸ—ï¸\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì„ ì‹œì‘í•˜ê¸° ì „ì— ë‹¤ìŒì„ ì™„ë£Œí•´ì•¼ í•©ë‹ˆë‹¤:\n",
        "\n",
        "ğŸ”² ğŸ“š **[Unit 2ì˜ Q-Learning ì´ë¡ ](https://huggingface.co/deep-rl-course/unit2/introduction)**ì„ í•™ìŠµí•˜ì„¸ìš” ğŸ¤—"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2ONOODsyrMU"
      },
      "source": [
        "## Q-Learningì— ëŒ€í•œ ê°„ëµí•œ ìš”ì•½"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V68VveLacfxJ"
      },
      "source": [
        "*Q-Learning*ì€ ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì‘ë™í•˜ëŠ” **ê°•í™” í•™ìŠµ(RL) ì•Œê³ ë¦¬ì¦˜**ì…ë‹ˆë‹¤:\n",
        "\n",
        "- *Q-í•¨ìˆ˜(Q-Function)*ë¥¼ í•™ìŠµí•˜ë©°, ì´ëŠ” **í–‰ë™ ê°€ì¹˜ í•¨ìˆ˜(action-value function)**ì…ë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” ë‚´ë¶€ ë©”ëª¨ë¦¬ë¡œ *Q-í…Œì´ë¸”(Q-table)*ì— **ëª¨ë“  ìƒíƒœ-í–‰ë™ ìŒì˜ ê°’ì„ ì €ì¥**í•©ë‹ˆë‹¤.\n",
        "\n",
        "- ì–´ë–¤ ìƒíƒœì™€ í–‰ë™ì´ ì£¼ì–´ì¡Œì„ ë•Œ, Q-í•¨ìˆ˜ëŠ” **Q-í…Œì´ë¸”ì—ì„œ í•´ë‹¹ ê°’**ì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤.\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/Q-function-2.jpg\" alt=\"Q function\"  width=\"100%\"/>\n",
        "\n",
        "- í›ˆë ¨ì´ ì™„ë£Œë˜ë©´, ìš°ë¦¬ëŠ” **ìµœì ì˜ Q-í•¨ìˆ˜**, ì¦‰ **ìµœì ì˜ Q-í…Œì´ë¸”**ì„ ì–»ê²Œ ë©ë‹ˆë‹¤.\n",
        "\n",
        "- ê·¸ë¦¬ê³  **ìµœì ì˜ Q-í•¨ìˆ˜**ë¥¼ ê°–ê²Œ ë˜ë©´, ê²°êµ­ **ê° ìƒíƒœë§ˆë‹¤ ìµœì ì˜ í–‰ë™ì„ ì•Œ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì´ëŠ” ê³§ ìµœì ì˜ ì •ì±…(optimal policy)**ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/link-value-policy.jpg\" alt=\"Link value policy\"  width=\"100%\"/>\n",
        "\n",
        "í•˜ì§€ë§Œ ì´ˆë°˜ì—ëŠ” **Q-í…Œì´ë¸”ì´ ì•„ë¬´ ì“¸ëª¨ ì—†ìŠµë‹ˆë‹¤.** ê° ìƒíƒœ-í–‰ë™ ìŒì— ëŒ€í•´ ì„ì˜ì˜ ê°’(ë³´í†µ 0ìœ¼ë¡œ ì´ˆê¸°í™”ë¨)ì„ ì£¼ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í™˜ê²½ì„ íƒí—˜í•˜ê³  Q-í…Œì´ë¸”ì„ ì ì°¨ ì—…ë°ì´íŠ¸í•˜ë©´ì„œ **ë” ë‚˜ì€ ê·¼ì‚¬ê°’**ì„ ì–»ê²Œ ë©ë‹ˆë‹¤.\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit2/q-learning.jpeg\" alt=\"q-learning.jpeg\" width=\"100%\"/>\n",
        "\n",
        "ë‹¤ìŒì€ Q-Learningì˜ ì˜ì‚¬ ì½”ë“œ(pseudocode)ì…ë‹ˆë‹¤:\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/Q-learning-2.jpg\" alt=\"Q-Learning\" width=\"100%\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEtx8Y8MqKfH"
      },
      "source": [
        "# ì²« ë²ˆì§¸ ê°•í™” í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì„ ì½”ë”©í•´ ë³´ê² ìŠµë‹ˆë‹¤. ğŸš€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kdxb1IhzTn0v"
      },
      "source": [
        "ì´ ì‹¤ìŠµì„ [ì¸ì¦ ê³¼ì •](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process)ì— í¬í•¨ì‹œí‚¤ê¸° ìœ„í•´ì„œëŠ”, í•™ìŠµì‹œí‚¨ Taxi ëª¨ë¸ì„ Hubì— ì—…ë¡œë“œí•˜ê³  **ê²°ê³¼ê°€ 4.5 ì´ìƒ**ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "ê²°ê³¼ë¥¼ í™•ì¸í•˜ë ¤ë©´, [ë¦¬ë”ë³´ë“œ](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)ë¡œ ì´ë™í•˜ì—¬ ë³¸ì¸ì˜ ëª¨ë¸ì„ ì°¾ìœ¼ì„¸ìš”.  \n",
        "**ê²°ê³¼ ê°’ = í‰ê·  ë³´ìƒ(mean_reward) - ë³´ìƒì˜ í‘œì¤€í¸ì°¨(std of reward)** ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì¸ì¦ ì ˆì°¨ì— ëŒ€í•œ ë” ìì„¸í•œ ì •ë³´ëŠ” ì•„ë˜ ë§í¬ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ ğŸ‘‰  \n",
        "[https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gpxC1_kqUYe"
      },
      "source": [
        "## ì˜ì¡´ì„± ì„¤ì¹˜ ë° ê°€ìƒ ë””ìŠ¤í”Œë ˆì´ ìƒì„± ğŸ”½\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ë¦¬í”Œë ˆì´ ì˜ìƒì„ ìƒì„±í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. Colabì—ì„œëŠ” **í™˜ê²½ì„ ë Œë”ë§í•˜ê¸° ìœ„í•œ ê°€ìƒ í™”ë©´(virtual screen)**ì´ í•„ìš”í•˜ë©°, ì´ë¥¼ í†µí•´ í”„ë ˆì„ì„ ë…¹í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ë”°ë¼ì„œ ì•„ë˜ ì…€ì€ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„¤ì¹˜í•˜ê³  ê°€ìƒ í™”ë©´ì„ ìƒì„± ë° ì‹¤í–‰í•©ë‹ˆë‹¤ ğŸ–¥\n",
        "\n",
        "ì„¤ì¹˜ë  ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
        "\n",
        "- `gymnasium`: FrozenLake-v1 â›„ ë° Taxi-v3 ğŸš• í™˜ê²½ì„ í¬í•¨í•©ë‹ˆë‹¤.  \n",
        "- `pygame`: FrozenLake-v1 ë° Taxi-v3ì˜ UI ë Œë”ë§ì— ì‚¬ìš©ë©ë‹ˆë‹¤.  \n",
        "- `numpy`: Q-í…Œì´ë¸”ì„ ë‹¤ë£¨ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.  \n",
        "\n",
        "ğŸ¤— Hugging Face HubëŠ” ëˆ„êµ¬ë‚˜ ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ì„ ê³µìœ í•˜ê³  íƒìƒ‰í•  ìˆ˜ ìˆëŠ” ì¤‘ì‹¬ í”Œë«í¼ì…ë‹ˆë‹¤. ë²„ì „ ê´€ë¦¬, ì§€í‘œ, ì‹œê°í™” ë“±ì˜ ê¸°ëŠ¥ì´ í¬í•¨ë˜ì–´ ìˆì–´ ë‹¤ë¥¸ ì‚¬ëŒë“¤ê³¼ ì‰½ê²Œ í˜‘ì—…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "Q-Learningì„ ì‚¬ìš©í•˜ëŠ” ëª¨ë“  ë”¥ RL ëª¨ë¸ì€ ì—¬ê¸°ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆì–´ìš” ğŸ‘‰  \n",
        "[https://huggingface.co/models?other=q-learning](https://huggingface.co/models?other=q-learning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XaULfDZDvrC"
      },
      "outputs": [],
      "source": [
        "!pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n71uTX7qqzz2"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y python3-opengl\n",
        "!apt install ffmpeg xvfb\n",
        "!pip3 install pyvirtualdisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6XC13pTfFiD"
      },
      "source": [
        "ìƒˆë¡œ ì„¤ì¹˜ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì ìš©í•˜ë ¤ë©´ **ëŸ°íƒ€ì„ì„ ì¬ì‹œì‘í•´ì•¼ í•  ë•Œê°€ ìˆìŠµë‹ˆë‹¤**.  \n",
        "ë‹¤ìŒ ì…€ì€ **ëŸ°íƒ€ì„ì„ ê°•ì œë¡œ ì¤‘ë‹¨ì‹œí‚¬ ê²ƒì´ë¯€ë¡œ, ì¬ì—°ê²° í›„ ì—¬ê¸°ë¶€í„° ì½”ë“œë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤**.  \n",
        "ì´ íŠ¸ë¦­ ë•ë¶„ì— **ê°€ìƒ í™”ë©´ì„ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kuZbWAkfHdg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaY1N4dBrabi"
      },
      "outputs": [],
      "source": [
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-7f-Swax_9x"
      },
      "source": [
        "## íŒ¨í‚¤ì§€ ì„í¬íŠ¸ ğŸ“¦\n",
        "\n",
        "ì„¤ì¹˜í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì™¸ì—ë„, ë‹¤ìŒê³¼ ê°™ì€ ì¶”ê°€ íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:\n",
        "\n",
        "- `random`: ë¬´ì‘ìœ„ ìˆ˜ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤ (ì—ì´ì „íŠ¸ì˜ Îµ-íƒìš• ì •ì±…ì—ì„œ í™œìš©ë©ë‹ˆë‹¤).  \n",
        "- `imageio`: ë¦¬í”Œë ˆì´ ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcNvOAQlysBJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "import random\n",
        "import imageio\n",
        "import os\n",
        "import tqdm\n",
        "\n",
        "import pickle5 as pickle\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp4-bXKIy1mQ"
      },
      "source": [
        "ì´ì œ Q-Learning ì•Œê³ ë¦¬ì¦˜ì„ ì½”ë”©í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤ ğŸ”¥"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xya49aNJWVvv"
      },
      "source": [
        "# Part 1: í”„ë¡œì¦Œ ë ˆì´í¬ â›„ (ë¯¸ë„ëŸ½ì§€ ì•Šì€ ë²„ì „)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAvihuHdy9tw"
      },
      "source": [
        "## [FrozenLake í™˜ê²½ â›„] ìƒì„± ë° ì´í•´í•˜ê¸°  \n",
        "---  \n",
        "\n",
        "ğŸ’¡ í™˜ê²½ì„ ì‚¬ìš©í•˜ê¸° ì‹œì‘í•  ë•Œ ì¢‹ì€ ìŠµê´€ì€ **ë¬¸ì„œë¥¼ í™•ì¸í•˜ëŠ” ê²ƒ**ì…ë‹ˆë‹¤.  \n",
        "\n",
        "ğŸ‘‰ https://gymnasium.farama.org/environments/toy_text/frozen_lake/  \n",
        "\n",
        "---  \n",
        "\n",
        "Q-Learning ì—ì´ì „íŠ¸ë¥¼ í›ˆë ¨ì‹œì¼œ **ì‹œì‘ ì§€ì (S)ì—ì„œ ëª©í‘œ ì§€ì (G)ê¹Œì§€ ì–¼ì–´ìˆëŠ” íƒ€ì¼(F)ë§Œ ë°Ÿê³  êµ¬ë©(H)ì€ í”¼í•´ì„œ ì´ë™**í•˜ë„ë¡ ë§Œë“¤ ê²ƒì…ë‹ˆë‹¤.  \n",
        "\n",
        "í™˜ê²½ í¬ê¸°ëŠ” ë‘ ê°€ì§€ ì¤‘ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  \n",
        "\n",
        "- `map_name=\"4x4\"`: 4x4 ê²©ì  \n",
        "- `map_name=\"8x8\"`: 8x8 ê²©ì  \n",
        "\n",
        "í™˜ê²½ì€ ë‘ ê°€ì§€ ëª¨ë“œë¥¼ ê°€ì§‘ë‹ˆë‹¤:  \n",
        "\n",
        "- `is_slippery=False`: ì–¼ì–´ìˆëŠ” í˜¸ìˆ˜ê°€ ë¯¸ë„ëŸ½ì§€ ì•Šì•„ì„œ ì—ì´ì „íŠ¸ê°€ **í•­ìƒ ì˜ë„í•œ ë°©í–¥ìœ¼ë¡œ ì´ë™**í•©ë‹ˆë‹¤ (ê²°ì •ì ).  \n",
        "- `is_slippery=True`: ì–¼ì–´ìˆëŠ” í˜¸ìˆ˜ê°€ ë¯¸ë„ëŸ¬ì›Œì„œ ì—ì´ì „íŠ¸ê°€ **í•­ìƒ ì˜ë„í•œ ë°©í–¥ìœ¼ë¡œ ì´ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤** (í™•ë¥ ì )."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaW_LHfS0PY2"
      },
      "source": [
        "ì§€ê¸ˆì€ ê°„ë‹¨í•˜ê²Œ 4x4 ë§µê³¼ ë¯¸ë„ëŸ½ì§€ ì•Šì€ ì„¤ì •ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.  \n",
        "í™˜ê²½ì„ ì‹œê°í™”í•˜ëŠ” ë°©ì‹ì„ ì§€ì •í•˜ëŠ” `render_mode`ë¼ëŠ” ë§¤ê°œë³€ìˆ˜ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.  \n",
        "ì´ë²ˆ ê²½ìš°ì—ëŠ” **í™˜ê²½ì˜ ì˜ìƒì„ ë§ˆì§€ë§‰ì— ê¸°ë¡í•˜ê³  ì‹¶ê¸° ë•Œë¬¸ì— render_modeë¥¼ `rgb_array`ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤**.\n",
        "\n",
        "[ë¬¸ì„œì— ì„¤ëª…ëœ ê²ƒì²˜ëŸ¼](https://gymnasium.farama.org/api/env/#gymnasium.Env.render), `\"rgb_array\"`ëŠ” í™˜ê²½ì˜ í˜„ì¬ ìƒíƒœë¥¼ ë‚˜íƒ€ë‚´ëŠ” **ë‹¨ì¼ í”„ë ˆì„ì„ ë°˜í™˜**í•©ë‹ˆë‹¤.  \n",
        "ì´ í”„ë ˆì„ì€ `(x, y, 3)` í˜•íƒœì˜ `np.ndarray`ë¡œ, `x`Ã—`y` í”½ì…€ ì´ë¯¸ì§€ì˜ RGB ê°’ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzJnb8O3y8up"
      },
      "outputs": [],
      "source": [
        "# 4x4 ë§µê³¼ â€‹â€‹ë¯¸ë„ëŸ½ì§€ ì•Šì€ ë²„ì „, render_mode=\"rgb_array\"ë¥¼ ì‚¬ìš©í•˜ì—¬ FrozenLake-v1 í™˜ê²½ì„ ë§Œë“­ë‹ˆë‹¤.\n",
        "env = gym.make() # TODO ì˜¬ë°”ë¥¸ ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji_UrI5l2zzn"
      },
      "source": [
        "### í•´ê²° ë°©ë²•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNxUbPMP0akP"
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"FrozenLake-v1\", map_name=\"4x4\", is_slippery=False, render_mode=\"rgb_array\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KASNViqL4tZn"
      },
      "source": [
        "ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©ì ì§€ì • ê²©ìë¥¼ ì§ì ‘ ë§Œë“¤ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:\n",
        "\n",
        "```python\n",
        "desc = [\"SFFF\", \"FHFH\", \"FFFH\", \"HFFG\"]\n",
        "gym.make('FrozenLake-v1', desc=desc, is_slippery=True)\n",
        "```\n",
        "\n",
        "í•˜ì§€ë§Œ ì§€ê¸ˆì€ **ê¸°ë³¸ í™˜ê²½**ì„ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXbTfdeJ1Xi9"
      },
      "source": [
        "### í™˜ê²½ì´ ì–´ë–»ê²Œ ìƒê²¼ëŠ”ì§€ ì‚´í´ë³´ì:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNPG0g_UGCfh"
      },
      "outputs": [],
      "source": [
        "# ìš°ë¦¬ëŠ” gym.make(\"<name_of_the_environment>\")ë¥¼ ì‚¬ìš©í•˜ì—¬ í™˜ê²½ì„ ìƒì„±í•©ë‹ˆë‹¤. - `is_slippery=False`: ë¯¸ë„ëŸ½ì§€ ì•Šì€ ì–¼ì–´ë¶™ì€ í˜¸ìˆ˜ í™˜ê²½ì—ì„œëŠ” ì—ì´ì „íŠ¸ê°€ í•­ìƒ ì˜ë„í•œ ë°©í–¥ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤ (ê²°ì •ë¡ ì ).\n",
        "print(\"_____ê´€ì°° ê³µê°„_____ \\n\")\n",
        "print(\"ê´€ì°° ê³µê°„:\", env.observation_space)\n",
        "print(\"ìƒ˜í”Œ ê´€ì°°ê°’:\", env.observation_space.sample())  # ì„ì˜ì˜ ê´€ì°°ê°’ ì¶œë ¥"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MXc15qFE0M9"
      },
      "source": [
        "`Observation Space Shape Discrete(16)`ì„ í†µí•´ ê´€ì°°ê°’ì´ ì •ìˆ˜ì´ë©°, ì´ëŠ” **ì—ì´ì „íŠ¸ì˜ í˜„ì¬ ìœ„ì¹˜ë¥¼ current_row * ncols + current_col (rowì™€ colì€ 0ë¶€í„° ì‹œì‘)** ìœ¼ë¡œ í‘œí˜„í•œë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì˜ˆë¥¼ ë“¤ì–´, 4x4 ë§µì—ì„œ ëª©í‘œ ìœ„ì¹˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: 3 * 4 + 3 = 15. ê°€ëŠ¥í•œ ê´€ì°°ê°’ì˜ ìˆ˜ëŠ” ë§µì˜ í¬ê¸°ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤. **ì˜ˆë¥¼ ë“¤ì–´, 4x4 ë§µì—ëŠ” 16ê°œì˜ ê°€ëŠ¥í•œ ê´€ì°°ê°’ì´ ìˆìŠµë‹ˆë‹¤.**\n",
        "\n",
        "ì˜ˆì‹œë¡œ, ìƒíƒœ(state) = 0ì€ ë‹¤ìŒê³¼ ê°™ì€ ëª¨ìŠµì…ë‹ˆë‹¤:\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit2/frozenlake.png\" alt=\"FrozenLake\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "We5WqOBGLoSm"
      },
      "outputs": [],
      "source": [
        "print(\"\\n _____í–‰ë™ ê³µê°„_____ \\n\")\n",
        "print(\"í–‰ë™ ê³µê°„ í¬ê¸°:\", env.action_space.n)\n",
        "print(\"ìƒ˜í”Œ í–‰ë™:\", env.action_space.sample())  # ì„ì˜ì˜ í–‰ë™ ì„ íƒ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyxXwkI2Magx"
      },
      "source": [
        "í–‰ë™ ê³µê°„(ì—ì´ì „íŠ¸ê°€ ì·¨í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥í•œ í–‰ë™ë“¤ì˜ ì§‘í•©)ì€ 4ê°œì˜ ì´ì‚°ì ì¸ í–‰ë™ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤ ğŸ®:  \n",
        "- 0: ì™¼ìª½ìœ¼ë¡œ ì´ë™  \n",
        "- 1: ì•„ë˜ë¡œ ì´ë™  \n",
        "- 2: ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì´ë™  \n",
        "- 3: ìœ„ë¡œ ì´ë™  \n",
        "\n",
        "ë³´ìƒ í•¨ìˆ˜ ğŸ’°:  \n",
        "- ëª©í‘œ ì§€ì  ë„ë‹¬: +1  \n",
        "- êµ¬ë©ì— ë¹ ì§: 0  \n",
        "- ì–¼ì–´ìˆëŠ” ì¹¸ ë„ë‹¬: 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pFhWblk3Awr"
      },
      "source": [
        "## Q-í…Œì´ë¸” ìƒì„± ë° ì´ˆê¸°í™” ğŸ—„ï¸\n",
        "\n",
        "(ğŸ‘€ ì˜ì‚¬ì½”ë“œì˜ Step 1)\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/Q-learning-2.jpg\" alt=\"Q-Learning\" width=\"100%\"/>\n",
        "\n",
        "ì´ì œ Q-í…Œì´ë¸”ì„ ì´ˆê¸°í™”í•  ì‹œê°„ì…ë‹ˆë‹¤!  \n",
        "ëª‡ ê°œì˜ í–‰(ìƒíƒœ)ê³¼ ì—´(í–‰ë™)ì„ ì‚¬ìš©í• ì§€ ì•Œê¸° ìœ„í•´, ìš°ë¦¬ëŠ” í–‰ë™ ê³µê°„ê³¼ ê´€ì°° ê³µê°„ì„ ì•Œì•„ì•¼ í•©ë‹ˆë‹¤.  \n",
        "ì´ ê°’ë“¤ì€ ì•ì—ì„œ ì•Œì•˜ì§€ë§Œ, ì•Œê³ ë¦¬ì¦˜ì´ ë‹¤ì–‘í•œ í™˜ê²½ì— ë§ê²Œ ì¼ë°˜í™”ë˜ë„ë¡ **í”„ë¡œê·¸ë˜ë°ì ìœ¼ë¡œ** ì–»ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.  \n",
        "\n",
        "Gymì€ ì´ë¥¼ ìœ„í•œ ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤:  \n",
        "`env.action_space.n`ì™€ `env.observation_space.n`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3ZCdluj3k0l"
      },
      "outputs": [],
      "source": [
        "state_space =\n",
        "print(\"There are \", state_space, \" possible states\")\n",
        "\n",
        "action_space =\n",
        "print(\"There are \", action_space, \" possible actions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCddoOXM3UQH"
      },
      "outputs": [],
      "source": [
        "# Q-í…Œì´ë¸”ì„ (ìƒíƒœ ê³µê°„, í–‰ë™ ê³µê°„) í¬ê¸°ë¡œ ìƒì„±í•˜ê³ , ê° ê°’ì„ 0ìœ¼ë¡œ ì´ˆê¸°í™”í•´ë´…ì‹œë‹¤. np.zerosëŠ” íŠœí”Œ (a, b)ë¥¼ í•„ìš”ë¡œ í•©ë‹ˆë‹¤.\n",
        "def initialize_q_table(state_space, action_space):\n",
        "  Qtable =\n",
        "  return Qtable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YfvrqRt3jdR"
      },
      "outputs": [],
      "source": [
        "Qtable_frozenlake = initialize_q_table(state_space, action_space)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67OdoKL63eDD"
      },
      "source": [
        "### í•´ê²° ë°©ë²•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuTKv3th3ohG"
      },
      "outputs": [],
      "source": [
        "state_space = env.observation_space.n\n",
        "print(\"There are \", state_space, \" possible states\")\n",
        "\n",
        "action_space = env.action_space.n\n",
        "print(\"There are \", action_space, \" possible actions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnrb_nX33fJo"
      },
      "outputs": [],
      "source": [
        "# Q-í…Œì´ë¸”ì„ (ìƒíƒœ ê³µê°„, í–‰ë™ ê³µê°„) í¬ê¸°ë¡œ ìƒì„±í•˜ê³ , ê° ê°’ì„ 0ìœ¼ë¡œ ì´ˆê¸°í™”í•´ë´…ì‹œë‹¤. np.zerosëŠ” íŠœí”Œ (a, b)ë¥¼ í•„ìš”ë¡œ í•©ë‹ˆë‹¤.\n",
        "def initialize_q_table(state_space, action_space):\n",
        "  Qtable = np.zeros((state_space, action_space))\n",
        "  return Qtable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0WlgkVO3Jf9"
      },
      "outputs": [],
      "source": [
        "Qtable_frozenlake = initialize_q_table(state_space, action_space)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Atll4Z774gri"
      },
      "source": [
        "## íƒìš•ì  ì •ì±… ì •ì˜ ğŸ¤–\n",
        "\n",
        "Q-Learningì€ **ì˜¤í”„-ì •ì±…** ì•Œê³ ë¦¬ì¦˜ì´ê¸° ë•Œë¬¸ì— ë‘ ê°€ì§€ ì •ì±…ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ëŠ” **í–‰ë™ì„ ì·¨í•  ë•Œì™€ ê°€ì¹˜ í•¨ìˆ˜ë¥¼ ì—…ë°ì´íŠ¸í•  ë•Œ ë‹¤ë¥¸ ì •ì±…ì„ ì‚¬ìš©í•œë‹¤**ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "- **ì—¡ì‹¤ë¡ -íƒìš•ì  ì •ì±…** (í–‰ë™ ì •ì±…)\n",
        "- **íƒìš•ì  ì •ì±…** (ê°€ì¹˜ í•¨ìˆ˜ ì—…ë°ì´íŠ¸ ì •ì±…)\n",
        "\n",
        "íƒìš•ì  ì •ì±…ì€ Q-Learning ì—ì´ì „íŠ¸ê°€ í›ˆë ¨ì„ ì™„ë£Œí–ˆì„ ë•Œ ìµœì¢…ì ìœ¼ë¡œ ê°€ì§€ê²Œ ë  ì •ì±…ì´ê¸°ë„ í•©ë‹ˆë‹¤. íƒìš•ì  ì •ì±…ì€ Q-í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ì—¬ í–‰ë™ì„ ì„ íƒí•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/off-on-4.jpg\" alt=\"Q-Learning\" width=\"100%\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3SCLmLX5bWG"
      },
      "outputs": [],
      "source": [
        "def greedy_policy(Qtable, state):\n",
        "  # ì°©ì·¨: ê°€ì¥ ë†’ì€ ìƒíƒœ-í–‰ë™ ê°’ì„ ê°€ì§„ í–‰ë™ì„ ì·¨í•˜ê¸°\n",
        "  action =\n",
        "\n",
        "  return action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2_-8b8z5k54"
      },
      "source": [
        "#### í•´ê²° ë°©ë²•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "se2OzWGW5kYJ"
      },
      "outputs": [],
      "source": [
        "def greedy_policy(Qtable, state):\n",
        "  # ì°©ì·¨: ê°€ì¥ ë†’ì€ ìƒíƒœ-í–‰ë™ ê°’ì„ ê°€ì§„ í–‰ë™ì„ ì·¨í•˜ê¸°\n",
        "  action = np.argmax(Qtable[state][:])\n",
        "\n",
        "  return action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flILKhBU3yZ7"
      },
      "source": [
        "## ì—¡ì‹¤ë¡ -íƒìš•ì  ì •ì±… ì •ì˜ ğŸ¤–\n",
        "\n",
        "ì—¡ì‹¤ë¡ -íƒìš•ì  ì •ì±…ì€ íƒìƒ‰/ì°©ì·¨ì˜ ê· í˜•ì„ ì²˜ë¦¬í•˜ëŠ” í›ˆë ¨ ì •ì±…ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì—¡ì‹¤ë¡ -íƒìš•ì  ì •ì±…ì˜ ì•„ì´ë””ì–´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
        "\n",
        "- *í™•ë¥  1â€Š-â€ŠÉ›* : **ì°©ì·¨**ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤ (ì¦‰, ì—ì´ì „íŠ¸ëŠ” ê°€ì¥ ë†’ì€ ìƒíƒœ-í–‰ë™ ê°’ì´ ìˆëŠ” í–‰ë™ì„ ì„ íƒí•©ë‹ˆë‹¤).\n",
        "  \n",
        "- *í™•ë¥  É›* : **íƒìƒ‰**ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤ (ë¬´ì‘ìœ„ í–‰ë™ì„ ì‹œë„í•©ë‹ˆë‹¤).\n",
        "\n",
        "í›ˆë ¨ì´ ì§„í–‰ë¨ì— ë”°ë¼ ì ì°¨ì ìœ¼ë¡œ **ì—¡ì‹¤ë¡  ê°’ì„ ì¤„ì—¬ê°€ë©°, íƒìƒ‰ì€ ì ì  ì ê²Œ í•˜ê³ , ì°©ì·¨ëŠ” ë” ë§ì´ í•˜ê²Œ ë©ë‹ˆë‹¤.**\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/Q-learning-4.jpg\" alt=\"Q-Learning\" width=\"100%\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Bj7x3in3_Pq"
      },
      "outputs": [],
      "source": [
        "def epsilon_greedy_policy(Qtable, state, epsilon):\n",
        "  # 0ê³¼ 1 ì‚¬ì´ì˜ ë¬´ì‘ìœ„ ìˆ«ì ìƒì„±\n",
        "  random_num =\n",
        "  # random_num > epsilonì´ë©´ --> ì°©ì·¨\n",
        "  if random_num > epsilon:\n",
        "    # í˜„ì¬ ìƒíƒœì—ì„œ ê°€ì¥ ë†’ì€ Qê°’ì„ ê°€ì§€ëŠ” í–‰ë™ ì„ íƒ\n",
        "    # np.argmaxê°€ ì—¬ê¸°ì„œ ìœ ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
        "    action =\n",
        "  # ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ --> íƒìƒ‰\n",
        "  else:\n",
        "    action = # ë¬´ì‘ìœ„ í–‰ë™ ì„ íƒ\n",
        "\n",
        "  return action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R5ej1fS4P2V"
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYxHuckr4LiG"
      },
      "outputs": [],
      "source": [
        "def epsilon_greedy_policy(Qtable, state, epsilon):\n",
        "  # 0ê³¼ 1 ì‚¬ì´ì˜ ë¬´ì‘ìœ„ ìˆ«ì ìƒì„±\n",
        "  random_num = random.uniform(0, 1)\n",
        "  \n",
        "  # random_num > epsilonì´ë©´ --> ì°©ì·¨\n",
        "  if random_num > epsilon:\n",
        "    # í˜„ì¬ ìƒíƒœì—ì„œ ê°€ì¥ ë†’ì€ Qê°’ì„ ê°€ì§€ëŠ” í–‰ë™ ì„ íƒ\n",
        "    # np.argmaxê°€ ì—¬ê¸°ì„œ ìœ ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
        "    action = greedy_policy(Qtable, state)\n",
        "  # ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ --> íƒìƒ‰\n",
        "  else:\n",
        "    # ë¬´ì‘ìœ„ í–‰ë™ ì„ íƒ\n",
        "    action = env.action_space.sample()\n",
        "\n",
        "  return action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW80DealcRtu"
      },
      "source": [
        "## í•˜ì´í¼íŒŒë¼ë¯¸í„° ì •ì˜ âš™ï¸\n",
        "\n",
        "íƒí—˜(exploration)ê³¼ ê´€ë ¨ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ê°€ì¥ ì¤‘ìš”í•œ ìš”ì†Œ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.\n",
        "\n",
        "- ì—ì´ì „íŠ¸ê°€ **ì¶©ë¶„íˆ ìƒíƒœ ê³µê°„ì„ íƒí—˜**í•˜ì—¬ ì˜¬ë°”ë¥¸ ê°€ì¹˜ ê·¼ì‚¬ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•´ì•¼ í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ epsilonì„ ì ì§„ì ìœ¼ë¡œ ê°ì†Œì‹œí‚¤ëŠ” ë°©ì‹ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
        "- epsilonì„ ë„ˆë¬´ ë¹ ë¥´ê²Œ ì¤„ì´ë©´ (decay_rateê°€ ë„ˆë¬´ í¬ë©´), **ì—ì´ì „íŠ¸ê°€ ë¬¸ì œë¥¼ í•´ê²°í•˜ì§€ ëª»í•˜ê³  ê°‡í ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤**. ì´ëŠ” ìƒíƒœ ê³µê°„ì„ ì¶©ë¶„íˆ íƒí—˜í•˜ì§€ ëª»í•´ í•™ìŠµì´ ë¶ˆì™„ì „í•´ì§€ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1tWn0tycWZ1"
      },
      "outputs": [],
      "source": [
        "# í•™ìŠµ íŒŒë¼ë¯¸í„°\n",
        "n_training_episodes = 10000  # ì „ì²´ í•™ìŠµ ì—í”¼ì†Œë“œ ìˆ˜\n",
        "learning_rate = 0.7          # í•™ìŠµë¥ \n",
        "\n",
        "# í‰ê°€ íŒŒë¼ë¯¸í„°\n",
        "n_eval_episodes = 100        # ì „ì²´ í‰ê°€(í…ŒìŠ¤íŠ¸) ì—í”¼ì†Œë“œ ìˆ˜\n",
        "\n",
        "# í™˜ê²½ íŒŒë¼ë¯¸í„°\n",
        "env_id = \"FrozenLake-v1\"     # í™˜ê²½ ì´ë¦„\n",
        "max_steps = 99               # ì—í”¼ì†Œë“œë‹¹ ìµœëŒ€ ìŠ¤í… ìˆ˜\n",
        "gamma = 0.95                 # ê°ê°€ìœ¨ (discount factor)\n",
        "eval_seed = []               # í‰ê°€ ì‹œ í™˜ê²½ì˜ ì‹œë“œ\n",
        "\n",
        "# íƒí—˜ íŒŒë¼ë¯¸í„°\n",
        "max_epsilon = 1.0             # ì´ˆê¸° íƒí—˜ í™•ë¥ \n",
        "min_epsilon = 0.05            # ìµœì†Œ íƒí—˜ í™•ë¥ \n",
        "decay_rate = 0.0005           # íƒí—˜ í™•ë¥ ì˜ ì§€ìˆ˜ ê°ì‡ ìœ¨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDb7Tdx8atfL"
      },
      "source": [
        "## í•™ìŠµ ë£¨í”„ ë©”ì„œë“œ ìƒì„±\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/Q-learning-2.jpg\" alt=\"Q-Learning\" width=\"100%\"/>\n",
        "\n",
        "í•™ìŠµ ë£¨í”„ëŠ” ë‹¤ìŒê³¼ ê°™ì€ íë¦„ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤:\n",
        "\n",
        "```\n",
        "ì „ì²´ í•™ìŠµ ì—í”¼ì†Œë“œ ìˆ˜ë§Œí¼ ë°˜ë³µ:\n",
        "\n",
        "  epsilon ê°ì†Œ (íƒí—˜ì´ ì ì  ëœ í•„ìš”í•´ì§)\n",
        "  í™˜ê²½ ì´ˆê¸°í™”\n",
        "\n",
        "    max_stepsë§Œí¼ ë°˜ë³µ:\n",
        "      epsilon-greedy ì •ì±…ì„ ì‚¬ìš©í•˜ì—¬ í–‰ë™ At ì„ íƒ\n",
        "      í–‰ë™ aë¥¼ ì·¨í•˜ê³ , ë‹¤ìŒ ìƒíƒœ s'ì™€ ë³´ìƒ r ê´€ì¸¡\n",
        "      Bellman ë°©ì •ì‹ì„ ì‚¬ìš©í•´ Qê°’ Q(s,a) ì—…ë°ì´íŠ¸:\n",
        "        Q(s,a) â† Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
        "      ì¢…ë£Œ ì¡°ê±´ì´ë©´ ì—í”¼ì†Œë“œ ì¢…ë£Œ\n",
        "      ë‹¤ìŒ ìƒíƒœë¥¼ í˜„ì¬ ìƒíƒœë¡œ ê°±ì‹ \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paOynXy3aoJW"
      },
      "outputs": [],
      "source": [
        "def train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable):\n",
        "  for episode in tqdm(range(n_training_episodes)):\n",
        "    # epsilon ê°ì†Œ (íƒí—˜ì´ ì ì  ëœ í•„ìš”í•´ì§€ë¯€ë¡œ)\n",
        "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
        "    # í™˜ê²½ ì´ˆê¸°í™”\n",
        "    state, info = env.reset()\n",
        "    step = 0\n",
        "    terminated = False\n",
        "    truncated = False\n",
        "\n",
        "    # ë°˜ë³µ\n",
        "    for step in range(max_steps):\n",
        "      # epsilon-greedy ì •ì±…ì„ ì‚¬ìš©í•˜ì—¬ At í–‰ë™ ì„ íƒ\n",
        "      action =\n",
        "\n",
        "      # At í–‰ë™ì„ ì·¨í•˜ê³  Rt+1ê³¼ St+1ì„ ê´€ì¸¡\n",
        "      # í–‰ë™ (a)ì„ ì·¨í•˜ê³  ê²°ê³¼ ìƒíƒœ(s')ì™€ ë³´ìƒ (r)ì„ ê´€ì°°í•˜ì„¸ìš”.\n",
        "      new_state, reward, terminated, truncated, info =\n",
        "\n",
        "      # Q(s,a) ì—…ë°ì´íŠ¸: Q(s,a) â† Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
        "      Qtable[state][action] =\n",
        "\n",
        "      # ì¢…ë£Œ ì¡°ê±´ì´ë©´ ì—í”¼ì†Œë“œ ì¢…ë£Œ\n",
        "      if terminated or truncated:\n",
        "        break\n",
        "\n",
        "      # ë‹¤ìŒ ìƒíƒœë¥¼ í˜„ì¬ ìƒíƒœë¡œ ê°±ì‹ \n",
        "      state = new_state\n",
        "  return Qtable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pnpk2ePoem3r"
      },
      "source": [
        "#### í•´ê²° ë°©ë²•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyZaYbUAeolw"
      },
      "outputs": [],
      "source": [
        "def train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable):\n",
        "  for episode in tqdm(range(n_training_episodes)):\n",
        "    # epsilon ê°ì†Œ (íƒí—˜ì´ ì ì  ëœ í•„ìš”í•´ì§€ë¯€ë¡œ)\n",
        "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
        "    # í™˜ê²½ ì´ˆê¸°í™”\n",
        "    state, info = env.reset()\n",
        "    step = 0\n",
        "    terminated = False\n",
        "    truncated = False\n",
        "\n",
        "    # ë°˜ë³µ\n",
        "    for step in range(max_steps):\n",
        "      # epsilon-greedy ì •ì±…ì„ ì‚¬ìš©í•˜ì—¬ At í–‰ë™ ì„ íƒ\n",
        "      action = epsilon_greedy_policy(Qtable, state, epsilon)\n",
        "\n",
        "      # At í–‰ë™ì„ ì·¨í•˜ê³  Rt+1ê³¼ St+1ì„ ê´€ì¸¡\n",
        "      # í–‰ë™ (a)ì„ ì·¨í•˜ê³  ê²°ê³¼ ìƒíƒœ(s')ì™€ ë³´ìƒ (r)ì„ ê´€ì°°í•˜ì„¸ìš”.\n",
        "      new_state, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "      # Q(s,a) ì—…ë°ì´íŠ¸: Q(s,a) â† Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
        "      Qtable[state][action] = Qtable[state][action] + learning_rate * (reward + gamma * np.max(Qtable[new_state]) - Qtable[state][action])\n",
        "\n",
        "      # ì¢…ë£Œ ì¡°ê±´ì´ë©´ ì—í”¼ì†Œë“œ ì¢…ë£Œ\n",
        "      if terminated or truncated:\n",
        "        break\n",
        "\n",
        "      # ë‹¤ìŒ ìƒíƒœë¥¼ í˜„ì¬ ìƒíƒœë¡œ ê°±ì‹ \n",
        "      state = new_state\n",
        "  return Qtable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLwKQ4tUdhGI"
      },
      "source": [
        "## Q-Learning ì—ì´ì „íŠ¸ í•™ìŠµ ğŸƒ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPBxfjJdTCOH"
      },
      "outputs": [],
      "source": [
        "Qtable_frozenlake = train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable_frozenlake)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVeEhUCrc30L"
      },
      "source": [
        "## ì´ì œ Q-Learning í…Œì´ë¸”ì´ ì–´ë–»ê²Œ ìƒê²¼ëŠ”ì§€ í™•ì¸í•´ë´…ì‹œë‹¤ ğŸ‘€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmfchsTITw4q"
      },
      "outputs": [],
      "source": [
        "Qtable_frozenlake"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUrWkxsHccXD"
      },
      "source": [
        "## í‰ê°€ ë°©ë²• ğŸ“\n",
        "\n",
        "- Q-Learning ì—ì´ì „íŠ¸ë¥¼ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•  í‰ê°€ ë°©ë²•ì„ ì •ì˜í–ˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNl0_JO2cbkm"
      },
      "outputs": [],
      "source": [
        "def evaluate_agent(env, max_steps, n_eval_episodes, Q, seed):\n",
        "  \"\"\"\n",
        "  Q-Learning ì—ì´ì „íŠ¸ë¥¼ ``n_eval_episodes`` ì—í”¼ì†Œë“œ ë™ì•ˆ í‰ê°€í•˜ê³  í‰ê·  ë³´ìƒê³¼ ë³´ìƒì˜ í‘œì¤€í¸ì°¨ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
        "  :param env: í‰ê°€ í™˜ê²½\n",
        "  :param max_steps: ì—í”¼ì†Œë“œë‹¹ ìµœëŒ€ ìŠ¤í… ìˆ˜\n",
        "  :param n_eval_episodes: ì—ì´ì „íŠ¸ë¥¼ í‰ê°€í•  ì—í”¼ì†Œë“œ ìˆ˜\n",
        "  :param Q: Q-í…Œì´ë¸”\n",
        "  :param seed: í‰ê°€ ì‹œ ì‚¬ìš©í•  ì‹œë“œ ë°°ì—´ (taxi-v3ì˜ ê²½ìš°)\n",
        "  \"\"\"\n",
        "  episode_rewards = []\n",
        "  for episode in tqdm(range(n_eval_episodes)):\n",
        "    if seed:\n",
        "      state, info = env.reset(seed=seed[episode])\n",
        "    else:\n",
        "      state, info = env.reset()\n",
        "    step = 0\n",
        "    truncated = False\n",
        "    terminated = False\n",
        "    total_rewards_ep = 0\n",
        "\n",
        "    for step in range(max_steps):\n",
        "      # ì£¼ì–´ì§„ ìƒíƒœì—ì„œ ìµœëŒ€ ì˜ˆìƒ ë¯¸ë˜ ë³´ìƒì„ ê°€ì§€ëŠ” í–‰ë™ ì„ íƒ\n",
        "      action = greedy_policy(Q, state)\n",
        "      new_state, reward, terminated, truncated, info = env.step(action)\n",
        "      total_rewards_ep += reward\n",
        "\n",
        "      if terminated or truncated:\n",
        "        break\n",
        "      state = new_state\n",
        "    episode_rewards.append(total_rewards_ep)\n",
        "  \n",
        "  mean_reward = np.mean(episode_rewards)\n",
        "  std_reward = np.std(episode_rewards)\n",
        "\n",
        "  return mean_reward, std_reward\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jJqjaoAnxUo"
      },
      "source": [
        "## Q-Learning ì—ì´ì „íŠ¸ í‰ê°€ ğŸ“ˆ\n",
        "\n",
        "- ë³´í†µ í‰ê·  ë³´ìƒì€ 1.0ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
        "- **í™˜ê²½ì€ ìƒëŒ€ì ìœ¼ë¡œ ì‰½ìŠµë‹ˆë‹¤**. ìƒíƒœ ê³µê°„ì´ ë§¤ìš° ì‘ì•„ì„œ (16ê°œ) ê·¸ë ‡ìŠµë‹ˆë‹¤. í™˜ê²½ì„ ë” ë³µì¡í•˜ê²Œ ë§Œë“¤ê³  ì‹¶ë‹¤ë©´, [ë¯¸ë„ëŸ¬ìš´ ë²„ì „](https://gymnasium.farama.org/environments/toy_text/frozen_lake/)ìœ¼ë¡œ ë°”ê¿”ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë²„ì „ì€ í™•ë¥ ì  ìš”ì†Œë¥¼ ë„ì…í•´ í™˜ê²½ì„ ë” ë³µì¡í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAgB7s0HEFMm"
      },
      "outputs": [],
      "source": [
        "# ìš°ë¦¬ ì—ì´ì „íŠ¸ë¥¼ í‰ê°€í•˜ì„¸ìš”.\n",
        "mean_reward, std_reward = evaluate_agent(env, max_steps, n_eval_episodes, Qtable_frozenlake, eval_seed)\n",
        "print(f\"Mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxaP3bPdg1DV"
      },
      "source": [
        "## í•™ìŠµëœ ëª¨ë¸ì„ Hubì— ê²Œì‹œí•˜ê¸° ğŸ”¥\n",
        "\n",
        "í•™ìŠµ í›„ ì¢‹ì€ ê²°ê³¼ë¥¼ í™•ì¸í–ˆìœ¼ë¯€ë¡œ, **í•œ ì¤„ì˜ ì½”ë“œë¡œ í•™ìŠµëœ ëª¨ë¸ì„ Hub ğŸ¤—ì— ê²Œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤**.\n",
        "\n",
        "ë‹¤ìŒì€ ëª¨ë¸ ì¹´ë“œì˜ ì˜ˆì‹œì…ë‹ˆë‹¤:\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit2/modelcard.png\" alt=\"Model card\" width=\"100%\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv0k1JQjpMq3"
      },
      "source": [
        "Hubì˜ ë‚´ë¶€ì—ì„œëŠ” git ê¸°ë°˜ ì €ì¥ì†Œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤ (gitì´ ë¬´ì—‡ì¸ì§€ ëª¨ë¥¸ë‹¤ê³  ê±±ì •í•˜ì§€ ë§ˆì„¸ìš”). ì¦‰, ì‹¤í—˜ì„ ì§„í–‰í•˜ê³  ì—ì´ì „íŠ¸ë¥¼ ê°œì„ í•˜ë©´ì„œ ìƒˆë¡œìš´ ë²„ì „ìœ¼ë¡œ ëª¨ë¸ì„ ì—…ë°ì´íŠ¸í•  ìˆ˜ ìˆë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ5LrR-joIHD"
      },
      "source": [
        "#### ì´ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jex3i9lZ8ksX"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi, snapshot_download\n",
        "from huggingface_hub.repocard import metadata_eval_result, metadata_save\n",
        "\n",
        "from pathlib import Path\n",
        "import datetime\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qo57HBn3W74O"
      },
      "outputs": [],
      "source": [
        "def record_video(env, Qtable, out_directory, fps=1):\n",
        "  \"\"\"\n",
        "  ì—ì´ì „íŠ¸ì˜ ì¬ìƒ ì˜ìƒì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "  :param env: í™˜ê²½\n",
        "  :param Qtable: ì—ì´ì „íŠ¸ì˜ Q-table\n",
        "  :param out_directory: ì¶œë ¥ ë””ë ‰í† ë¦¬\n",
        "  :param fps: ì´ˆë‹¹ í”„ë ˆì„ ìˆ˜ (taxi-v3ì™€ frozenlake-v1ì—ì„œëŠ” 1ì„ ì‚¬ìš©)\n",
        "  \"\"\"\n",
        "  images = []\n",
        "  terminated = False\n",
        "  truncated = False\n",
        "  state, info = env.reset(seed=random.randint(0,500))\n",
        "  img = env.render()\n",
        "  images.append(img)\n",
        "  while not terminated or truncated:\n",
        "    # ì£¼ì–´ì§„ ìƒíƒœì—ì„œ ìµœëŒ€ ì˜ˆìƒ ë¯¸ë˜ ë³´ìƒì„ ê°€ì§€ëŠ” í–‰ë™ ì„ íƒ\n",
        "    action = np.argmax(Qtable[state][:])\n",
        "    state, reward, terminated, truncated, info = env.step(action)  # ë…¹í™” ë¡œì§ì„ ìœ„í•´ ìƒíƒœëŠ” ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤\n",
        "    img = env.render()\n",
        "    images.append(img)\n",
        "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4mdUTKkGnUd"
      },
      "outputs": [],
      "source": [
        "def push_to_hub(\n",
        "    repo_id, model, env, video_fps=1, local_repo_path=\"hub\"\n",
        "):\n",
        "    \"\"\"\n",
        "    í‰ê°€, ë¹„ë””ì˜¤ ìƒì„± ë° í—ˆê¹… í˜ì´ìŠ¤ í—ˆë¸Œì— ëª¨ë¸ ì—…ë¡œë“œ.\n",
        "    ì´ ë©”ì„œë“œëŠ” ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:\n",
        "    - ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
        "    - ëª¨ë¸ ì¹´ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "    - ì—ì´ì „íŠ¸ì˜ ì¬ìƒ ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "    - ëª¨ë“  ê²ƒì„ í—ˆë¸Œì— í‘¸ì‹œí•©ë‹ˆë‹¤.\n",
        "\n",
        "    :param ë ˆí¬_id: í—ˆê¹… í˜ì´ìŠ¤ í—ˆë¸Œì˜ ëª¨ë¸ ë ˆí¬ì§€í† ë¦¬ ID\n",
        "    :param í™˜ê²½\n",
        "    :param ë¹„ë””ì˜¤_fps: ë¹„ë””ì˜¤ ì¬ìƒì„ ê¸°ë¡í•  ì´ˆë‹¹ í”„ë ˆì„ ìˆ˜\n",
        "    (taxi-v3 ë° frozenlake-v1ì—ì„œëŠ” 1ì„ ì‚¬ìš©í•©ë‹ˆë‹¤)\n",
        "    :param ë¡œì»¬_ë ˆí¬_ê²½ë¡œ: ë¡œì»¬ ë ˆí¬ì§€í† ë¦¬ê°€ ìˆëŠ” ê²½ë¡œ\n",
        "    \"\"\"\n",
        "    _, repo_name = repo_id.split(\"/\")\n",
        "\n",
        "    eval_env = env\n",
        "    api = HfApi()\n",
        "\n",
        "    # Step 1: ë ˆí¬ì§€í† ë¦¬ ìƒì„±\n",
        "    repo_url = api.create_repo(\n",
        "        repo_id=repo_id,\n",
        "        exist_ok=True,\n",
        "    )\n",
        "\n",
        "    # Step 2: íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
        "    repo_local_path = Path(snapshot_download(repo_id=repo_id))\n",
        "\n",
        "    # Step 3: ëª¨ë¸ ì €ì¥\n",
        "    if env.spec.kwargs.get(\"map_name\"):\n",
        "        model[\"map_name\"] = env.spec.kwargs.get(\"map_name\")\n",
        "        if env.spec.kwargs.get(\"is_slippery\", \"\") == False:\n",
        "            model[\"slippery\"] = False\n",
        "\n",
        "    # ëª¨ë¸ í”¼í´ë§\n",
        "    with open((repo_local_path) / \"q-learning.pkl\", \"wb\") as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "    # Step 4: ëª¨ë¸ í‰ê°€ ë° í‰ê°€ ë©”íŠ¸ë¦­ í¬í•¨í•œ JSON ìƒì„±\n",
        "    mean_reward, std_reward = evaluate_agent(\n",
        "        eval_env, model[\"max_steps\"], model[\"n_eval_episodes\"], model[\"qtable\"], model[\"eval_seed\"]\n",
        "    )\n",
        "\n",
        "    evaluate_data = {\n",
        "        \"env_id\": model[\"env_id\"],\n",
        "        \"mean_reward\": mean_reward,\n",
        "        \"n_eval_episodes\": model[\"n_eval_episodes\"],\n",
        "        \"eval_datetime\": datetime.datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    # í‰ê°€ ê²°ê³¼ë¥¼ í¬í•¨í•œ \"results.json\" íŒŒì¼ ìƒì„±\n",
        "    with open(repo_local_path / \"results.json\", \"w\") as outfile:\n",
        "        json.dump(evaluate_data, outfile)\n",
        "\n",
        "    # Step 5: ëª¨ë¸ ì¹´ë“œ ìƒì„±\n",
        "    env_name = model[\"env_id\"]\n",
        "    if env.spec.kwargs.get(\"map_name\"):\n",
        "        env_name += \"-\" + env.spec.kwargs.get(\"map_name\")\n",
        "\n",
        "    if env.spec.kwargs.get(\"is_slippery\", \"\") == False:\n",
        "        env_name += \"-\" + \"no_slippery\"\n",
        "\n",
        "    metadata = {}\n",
        "    metadata[\"tags\"] = [env_name, \"q-learning\", \"reinforcement-learning\", \"custom-implementation\"]\n",
        "\n",
        "    # ë©”íŠ¸ë¦­ ì¶”ê°€\n",
        "    eval = metadata_eval_result(\n",
        "        model_pretty_name=repo_name,\n",
        "        task_pretty_name=\"reinforcement-learning\",\n",
        "        task_id=\"reinforcement-learning\",\n",
        "        metrics_pretty_name=\"mean_reward\",\n",
        "        metrics_id=\"mean_reward\",\n",
        "        metrics_value=f\"{mean_reward:.2f} +/- {std_reward:.2f}\",\n",
        "        dataset_pretty_name=env_name,\n",
        "        dataset_id=env_name,\n",
        "    )\n",
        "\n",
        "    # ë‘ ë”•ì…”ë„ˆë¦¬ ë³‘í•©\n",
        "    metadata = {**metadata, **eval}\n",
        "\n",
        "    model_card = f\"\"\"\n",
        "  # **Q-Learning** Agent playing1 **{env_id}**\n",
        "  This is a trained model of a **Q-Learning** agent playing **{env_id}** .\n",
        "\n",
        "  ## Usage\n",
        "\n",
        "  ```python\n",
        "\n",
        "  model = load_from_hub(repo_id=\"{repo_id}\", filename=\"q-learning.pkl\")\n",
        "\n",
        "  # Don't forget to check if you need to add additional attributes (is_slippery=False etc)\n",
        "  env = gym.make(model[\"env_id\"])\n",
        "  ```\n",
        "  \"\"\"\n",
        "\n",
        "    evaluate_agent(env, model[\"max_steps\"], model[\"n_eval_episodes\"], model[\"qtable\"], model[\"eval_seed\"])\n",
        "\n",
        "    readme_path = repo_local_path / \"README.md\"\n",
        "    readme = \"\"\n",
        "    print(readme_path.exists())\n",
        "    if readme_path.exists():\n",
        "        with readme_path.open(\"r\", encoding=\"utf8\") as f:\n",
        "            readme = f.read()\n",
        "    else:\n",
        "        readme = model_card\n",
        "\n",
        "    with readme_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(readme)\n",
        "\n",
        "    # Readme ë©”íƒ€ë°ì´í„°ì— ë©”íŠ¸ë¦­ ì €ì¥\n",
        "    metadata_save(readme_path, metadata)\n",
        "\n",
        "    # Step 6: ë¹„ë””ì˜¤ ë…¹í™”\n",
        "    video_path = repo_local_path / \"replay.mp4\"\n",
        "    record_video(env, model[\"qtable\"], video_path, video_fps)\n",
        "\n",
        "    # Step 7. ëª¨ë“  ê²ƒì„ Hubì— í‘¸ì‹œ\n",
        "    api.upload_folder(\n",
        "        repo_id=repo_id,\n",
        "        folder_path=repo_local_path,\n",
        "        path_in_repo=\".\",\n",
        "    )\n",
        "\n",
        "    print(\"ëª¨ë¸ì´ Hubì— ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ëª¨ë¸ì„ ì—¬ê¸°ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: \", repo_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81J6cet_ogSS"
      },
      "source": [
        "### .\n",
        "\n",
        "`push_to_hub`ë¥¼ ì‚¬ìš©í•˜ë©´ **ì—ì´ì „íŠ¸ë¥¼ í‰ê°€í•˜ê³ , ì¬ìƒ ì˜ìƒì„ ê¸°ë¡í•˜ê³ , ëª¨ë¸ ì¹´ë“œë¥¼ ìƒì„±í•˜ì—¬ Hubì— í‘¸ì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤**.\n",
        "\n",
        "ì´ ë°©ì‹ìœ¼ë¡œ:\n",
        "- **ìš°ë¦¬ì˜ ì‘ì—…ì„ ë³´ì—¬ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤** ğŸ”¥\n",
        "- **ì—ì´ì „íŠ¸ê°€ í”Œë ˆì´í•˜ëŠ” ëª¨ìŠµì„ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤** ğŸ‘€\n",
        "- **ë‹¤ë¥¸ ì‚¬ëŒë“¤ì´ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì—ì´ì „íŠ¸ë¥¼ ì»¤ë®¤ë‹ˆí‹°ì™€ ê³µìœ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤** ğŸ’¾\n",
        "- **ë¦¬ë”ë³´ë“œë¥¼ í†µí•´ ì—ì´ì „íŠ¸ì˜ ì„±ëŠ¥ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ ğŸ†** ğŸ‘‰ [Deep Reinforcement Learning Leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWnFC0iZooTw"
      },
      "source": [
        "ëª¨ë¸ì„ ì»¤ë®¤ë‹ˆí‹°ì™€ ê³µìœ í•˜ë ¤ë©´ ì„¸ ê°€ì§€ ë‹¨ê³„ë¥¼ ë” ë”°ë¼ì•¼ í•©ë‹ˆë‹¤:\n",
        "\n",
        "1ï¸âƒ£ (ì•„ì§ í•˜ì§€ ì•Šì•˜ë‹¤ë©´) Hugging Faceì— ê³„ì •ì„ ìƒì„±í•˜ì„¸ìš” â¡ [https://huggingface.co/join](https://huggingface.co/join)\n",
        "\n",
        "2ï¸âƒ£ ë¡œê·¸ì¸ í›„, Hugging Face ì›¹ì‚¬ì´íŠ¸ì—ì„œ ì¸ì¦ í† í°ì„ ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "- ìƒˆë¡œìš´ í† í°ì„ ìƒì„±í•˜ë ¤ë©´ [ì—¬ê¸°](https://huggingface.co/settings/tokens)ì—ì„œ **ì“°ê¸° ì—­í• **ë¡œ ìƒì„±í•˜ì„¸ìš”.\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg\" alt=\"Create HF Token\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QB5nIcxR8paT"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyWc1x3-o3xG"
      },
      "source": [
        "Google Colabì´ë‚˜ Jupyter Notebookì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°, ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ëŒ€ì‹  ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤: `huggingface-cli login`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc5AfUeFo3xH"
      },
      "source": [
        "3ï¸âƒ£ ì´ì œ `push_to_hub()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ëœ ì—ì´ì „íŠ¸ë¥¼ ğŸ¤— Hubì— í‘¸ì‹œí•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤ ğŸ”¥\n",
        "\n",
        "- **ëª¨ë¸ ë”•ì…”ë„ˆë¦¬**ë¥¼ ìƒì„±í•˜ì—¬ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì™€ Q_tableì„ í¬í•¨ì‹œì¼œì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiMqxqVHg0I4"
      },
      "outputs": [],
      "source": [
        "model = {\n",
        "    \"env_id\": env_id,\n",
        "    \"max_steps\": max_steps,\n",
        "    \"n_training_episodes\": n_training_episodes,\n",
        "    \"n_eval_episodes\": n_eval_episodes,\n",
        "    \"eval_seed\": eval_seed,\n",
        "\n",
        "    \"learning_rate\": learning_rate,\n",
        "    \"gamma\": gamma,\n",
        "\n",
        "    \"max_epsilon\": max_epsilon,\n",
        "    \"min_epsilon\": min_epsilon,\n",
        "    \"decay_rate\": decay_rate,\n",
        "\n",
        "    \"qtable\": Qtable_frozenlake\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kld-AEso3xH"
      },
      "source": [
        "`push_to_hub` í•¨ìˆ˜ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì±„ì›Œë´…ì‹œë‹¤:\n",
        "\n",
        "- `repo_id`: ìƒì„±ë˜ê±°ë‚˜ ì—…ë°ì´íŠ¸ë  Hugging Face Hub ì €ì¥ì†Œì˜ ì´ë¦„  \n",
        "(`repo_id = {username}/{repo_name}`)  \n",
        "ğŸ’¡ ì¢‹ì€ `repo_id` ì˜ˆì‹œ: `{username}/q-{env_id}`\n",
        "- `model`: í•˜ì´í¼íŒŒë¼ë¯¸í„°ì™€ Qtableì„ í¬í•¨í•œ ëª¨ë¸ ë”•ì…”ë„ˆë¦¬\n",
        "- `env`: í™˜ê²½\n",
        "- `commit_message`: ì»¤ë°‹ ë©”ì‹œì§€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sBo2umnXpPd"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpOTtSt83kPZ"
      },
      "outputs": [],
      "source": [
        "username = \"\" # ì´ê²ƒì„ ì±„ìš°ì„¸ìš”\n",
        "repo_name = \"q-FrozenLake-v1-4x4-noSlippery\"\n",
        "push_to_hub(\n",
        "    repo_id=f\"{username}/{repo_name}\",\n",
        "    model=model,\n",
        "    env=env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2875IGsprzq"
      },
      "source": [
        "ì¶•í•˜í•©ë‹ˆë‹¤ ğŸ¥³ ì²˜ìŒë¶€í„° ì§ì ‘ êµ¬í˜„í•˜ê³ , í•™ìŠµì‹œí‚¤ê³ , ì²« ë²ˆì§¸ ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ë¥¼ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤.  \n",
        "`FrozenLake-v1 no_slippery`ëŠ” ë§¤ìš° ê°„ë‹¨í•œ í™˜ê²½ì´ì—ˆìœ¼ë‹ˆ, ì´ì œ ë” ì–´ë ¤ìš´ í™˜ê²½ì— ë„ì „í•´ë´…ì‹œë‹¤ ğŸ”¥."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18lN8Bz7yvLt"
      },
      "source": [
        "# Part 2: Taxi-v3 ğŸš–\n",
        "\n",
        "## `Taxi-v3 ğŸš•` ë§Œë“¤ê³  ì´í•´í•˜ê¸°  \n",
        "---\n",
        "\n",
        "ğŸ’¡ í™˜ê²½ì„ ì²˜ìŒ ì‚¬ìš©í•  ë•ŒëŠ” ë¬¸ì„œë¥¼ í™•ì¸í•˜ëŠ” ìŠµê´€ì„ ë“¤ì´ì„¸ìš”\n",
        "\n",
        "ğŸ‘‰ https://gymnasium.farama.org/environments/toy_text/taxi/\n",
        "\n",
        "---\n",
        "\n",
        "`Taxi-v3` ğŸš•ì—ì„œëŠ” ê²©ì ì„¸ê³„(grid world)ì— R(ë¹¨ê°•), G(ì´ˆë¡), Y(ë…¸ë‘), B(íŒŒë‘) ë„¤ ê°œì˜ ì§€ì •ëœ ìœ„ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì—í”¼ì†Œë“œê°€ ì‹œì‘ë˜ë©´ **íƒì‹œëŠ” ë¬´ì‘ìœ„ ì¹¸ì—ì„œ ì‹œì‘**í•˜ê³ , ìŠ¹ê°ë„ ë¬´ì‘ìœ„ ìœ„ì¹˜ì— ìˆìŠµë‹ˆë‹¤.  \n",
        "íƒì‹œëŠ” ìŠ¹ê° ìœ„ì¹˜ë¡œ ì´ë™í•˜ì—¬ **ìŠ¹ê°ì„ íƒœìš´ ë’¤**, ìŠ¹ê°ì˜ ëª©ì ì§€(ì§€ì •ëœ ë„¤ ìœ„ì¹˜ ì¤‘ í•˜ë‚˜)ë¡œ ì´ë™í•˜ê³  **ìŠ¹ê°ì„ í•˜ì°¨**ì‹œí‚µë‹ˆë‹¤.  \n",
        "ìŠ¹ê°ì´ í•˜ì°¨ë˜ë©´ ì—í”¼ì†Œë“œê°€ ì¢…ë£Œë©ë‹ˆë‹¤.\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit2/taxi.png\" alt=\"Taxi\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gL0wpeO8gpej"
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"Taxi-v3\", render_mode=\"rgb_array\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBOaXgtsrmtT"
      },
      "source": [
        "**500ê°œì˜ ì´ì‚° ìƒíƒœ**ê°€ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” **íƒì‹œ ìœ„ì¹˜ 25ê°€ì§€, ìŠ¹ê°ì˜ ê°€ëŠ¥í•œ ìœ„ì¹˜ 5ê°€ì§€** (ìŠ¹ê°ì´ íƒì‹œ ì•ˆì— ìˆëŠ” ê²½ìš° í¬í•¨), ê·¸ë¦¬ê³  **ëª©ì ì§€ ìœ„ì¹˜ 4ê°€ì§€**ê°€ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_TPNaGSZrgqA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are  500  possible states\n"
          ]
        }
      ],
      "source": [
        "state_space = env.observation_space.n\n",
        "print(\"There are \", state_space, \" possible states\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CdeeZuokrhit"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are  6  possible actions\n"
          ]
        }
      ],
      "source": [
        "action_space = env.action_space.n\n",
        "print(\"There are \", action_space, \" possible actions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1r50Advrh5Q"
      },
      "source": [
        "í–‰ë™ ê³µê°„ (ì—ì´ì „íŠ¸ê°€ ì·¨í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥í•œ í–‰ë™ë“¤ì˜ ì§‘í•©)ì€ **6ê°œì˜ ì´ìš© ê°€ëŠ¥í•œ í–‰ë™ ğŸ®**ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ì´ì‚°ì  ê³µê°„ì…ë‹ˆë‹¤:\n",
        "\n",
        "- 0: ë‚¨ìª½ìœ¼ë¡œ ì´ë™\n",
        "- 1: ë¶ìª½ìœ¼ë¡œ ì´ë™\n",
        "- 2: ë™ìª½ìœ¼ë¡œ ì´ë™\n",
        "- 3: ì„œìª½ìœ¼ë¡œ ì´ë™\n",
        "- 4: ìŠ¹ê° íƒœìš°ê¸°\n",
        "- 5: ìŠ¹ê° ë‚´ë ¤ì£¼ê¸°\n",
        "\n",
        "ë³´ìƒ í•¨ìˆ˜ ğŸ’°:\n",
        "\n",
        "- ë‹¤ë¥¸ ë³´ìƒì´ íŠ¸ë¦¬ê±°ë˜ì§€ ì•ŠëŠ” í•œ, ë‹¨ê³„ë‹¹ -1.\n",
        "- ìŠ¹ê° ì „ë‹¬ ì‹œ +20.\n",
        "- â€œìŠ¹ê° íƒœìš°ê¸°â€ ë° â€œìŠ¹ê° ë‚´ë ¤ì£¼ê¸°â€ í–‰ë™ì„ ë¶ˆë²•ì ìœ¼ë¡œ ì‹¤í–‰ ì‹œ -10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "US3yDXnEtY9I"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]]\n",
            "Q-table shape:  (500, 6)\n"
          ]
        }
      ],
      "source": [
        "# state_size í–‰ê³¼ action_size ì—´(500x6)ì„ ê°–ëŠ” Q í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "Qtable_taxi = initialize_q_table(state_space, action_space)\n",
        "print(Qtable_taxi)\n",
        "print(\"Q-table shape: \", Qtable_taxi .shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUMKPH0_LJyH"
      },
      "source": [
        "## í•˜ì´í¼íŒŒë¼ë¯¸í„° ì •ì˜ âš™ï¸\n",
        "\n",
        "âš  EVAL_SEEDë¥¼ ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”: eval_seed ë°°ì—´ì€ **ëª¨ë“  í•™ìš°ì—ê²Œ ë™ì¼í•œ íƒì‹œ ì‹œì‘ ìœ„ì¹˜ë¡œ ì—ì´ì „íŠ¸ë¥¼ í‰ê°€í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "AB6n__hhg7YS"
      },
      "outputs": [],
      "source": [
        "# í›ˆë ¨ íŒŒë¼ë¯¸í„°\n",
        "n_training_episodes = 25000   # ì´ í›ˆë ¨ ì—í”¼ì†Œë“œ ìˆ˜\n",
        "learning_rate = 0.7           # í•™ìŠµë¥ \n",
        "\n",
        "# í‰ê°€ íŒŒë¼ë¯¸í„°\n",
        "n_eval_episodes = 100         # ì´ í…ŒìŠ¤íŠ¸ ì—í”¼ì†Œë“œ ìˆ˜\n",
        "\n",
        "# EVAL_SEED ìˆ˜ì • ê¸ˆì§€\n",
        "eval_seed = [16,54,165,177,191,191,120,80,149,178,48,38,6,125,174,73,50,172,100,148,146,6,25,40,68,148,49,167,9,97,164,176,61,7,54,55,\n",
        "  161,131,184,51,170,12,120,113,95,126,51,98,36,135,54,82,45,95,89,59,95,124,9,113,58,85,51,134,121,169,105,21,30,11,50,65,12,43,82,145,152,97,106,55,31,85,38,\n",
        "  112,102,168,123,97,21,83,158,26,80,63,5,81,32,11,28,148] # í‰ê°€ ì‹œë“œ, ì´ëŠ” ëª¨ë“  í•™ìš°ì˜ ì—ì´ì „íŠ¸ê°€ ë™ì¼í•œ íƒì‹œ ì‹œì‘ ìœ„ì¹˜ì—ì„œ í›ˆë ¨ë˜ë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤\n",
        "                                                         # ê° ì‹œë“œëŠ” íŠ¹ì • ì‹œì‘ ìƒíƒœë¥¼ ê°€ì§‘ë‹ˆë‹¤\n",
        "\n",
        "# í™˜ê²½ íŒŒë¼ë¯¸í„°\n",
        "env_id = \"Taxi-v3\"            # í™˜ê²½ ì´ë¦„\n",
        "max_steps = 99                # ì—í”¼ì†Œë“œë‹¹ ìµœëŒ€ ìŠ¤í… ìˆ˜\n",
        "gamma = 0.95                  # ê°ê°€ìœ¨ (í• ì¸ìœ¨)\n",
        "\n",
        "# íƒí—˜ íŒŒë¼ë¯¸í„°\n",
        "max_epsilon = 1.0             # ì‹œì‘ ì‹œ íƒí—˜ í™•ë¥ \n",
        "min_epsilon = 0.05            # ìµœì†Œ íƒí—˜ í™•ë¥ \n",
        "decay_rate = 0.005            # íƒí—˜ í™•ë¥ ì˜ ì§€ìˆ˜ ê°ì†Œìœ¨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TMORo1VLTsX"
      },
      "source": [
        "## Q-Learning ì—ì´ì „íŠ¸ í›ˆë ¨ì‹œí‚¤ê¸° ğŸƒ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "WwP3Y2z2eS-K"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "834a957357d1408fb74bf831ce046171",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/25000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "array([[  0.        ,   0.        ,   0.        ,   0.        ,\n",
              "          0.        ,   0.        ],\n",
              "       [  2.75200369,   3.94947757,   2.75200369,   3.94947757,\n",
              "          5.20997639,  -5.05052243],\n",
              "       [  7.93349184,   9.40344144,   7.93349184,   9.40367562,\n",
              "         10.9512375 ,   0.40367548],\n",
              "       ...,\n",
              "       [ -3.09408412,  12.58025   ,  -2.9070066 ,  -3.8221694 ,\n",
              "         -2.2027986 , -10.62089056],\n",
              "       [ -3.88608682,   6.53681724,  -3.95785867,  -4.13398518,\n",
              "        -12.16948305,  -5.57355163],\n",
              "       [ -1.3755    ,  -1.3755    ,  15.44934586,  18.        ,\n",
              "          5.59967048,   6.93507486]])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Qtable_taxi = train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable_taxi)\n",
        "Qtable_taxi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPdu0SueLVl2"
      },
      "source": [
        "## ëª¨ë¸ ë”•ì…”ë„ˆë¦¬ ìƒì„± ğŸ’¾ ë° í›ˆë ¨ëœ ëª¨ë¸ í—ˆë¸Œì— ê²Œì‹œ ğŸ”¥\n",
        "\n",
        "- ì¬í˜„ì„±ì„ ìœ„í•œ ëª¨ë“  í›ˆë ¨ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì™€ Q-í…Œì´ë¸”ì„ í¬í•¨í•  ëª¨ë¸ ë”•ì…”ë„ˆë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0a1FpE_3hNYr"
      },
      "outputs": [],
      "source": [
        "model = {\n",
        "    \"env_id\": env_id,\n",
        "    \"max_steps\": max_steps,\n",
        "    \"n_training_episodes\": n_training_episodes,\n",
        "    \"n_eval_episodes\": n_eval_episodes,\n",
        "    \"eval_seed\": eval_seed,\n",
        "\n",
        "    \"learning_rate\": learning_rate,\n",
        "    \"gamma\": gamma,\n",
        "\n",
        "    \"max_epsilon\": max_epsilon,\n",
        "    \"min_epsilon\": min_epsilon,\n",
        "    \"decay_rate\": decay_rate,\n",
        "\n",
        "    \"qtable\": Qtable_taxi\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhQtiQozhOn1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84a9eb9a77494526b6226c961a97e7a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f000ee6a1daa466e94d9161a73e95ccc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcdc712ad6d54d8dbaa85531aa210946",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c85f473d943b4f54ae3f986ec193e8bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (550, 350) to (560, 352) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ac22a7f07b84a13800c2a94b5fec1eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "replay.mp4:   0%|          | 0.00/117k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d63e1f19c61f48e5918b5156a8139dcb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "q-learning.pkl:   0%|          | 0.00/24.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed5907e11e2e4fdea57cf6a1ef950778",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ëª¨ë¸ì´ Hubì— ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ëª¨ë¸ì„ ì—¬ê¸°ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  https://huggingface.co/Yeongi/q-Taxi-v3\n"
          ]
        }
      ],
      "source": [
        "username = \"\" # ì´ê²ƒì„ ì±„ìš°ì„¸ìš”\n",
        "repo_name = \"\" # ì´ê²ƒì„ ì±„ìš°ì„¸ìš”\n",
        "push_to_hub(\n",
        "    repo_id=f\"{username}/{repo_name}\",\n",
        "    model=model,\n",
        "    env=env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgSdjgbIpRti"
      },
      "source": [
        "ì´ì œ ëª¨ë¸ì´ Hugging Face Hubì— ì—…ë¡œë“œë˜ì—ˆìœ¼ë‹ˆ, ë¦¬ë”ë³´ë“œë¥¼ í†µí•´ ì—¬ëŸ¬ë¶„ì˜ `Taxi-v3` ê²°ê³¼ë¥¼ ë‹¤ë¥¸ í•™ìŠµìë“¤ê³¼ ë¹„êµí•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤ ğŸ† ğŸ‘‰ https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit2/taxi-leaderboard.png\" alt=\"Taxi Leaderboard\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzgIO70c0bu2"
      },
      "source": [
        "# Part 3: í—ˆë¸Œì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸° ğŸ”½\n",
        "\n",
        "Hugging Face Hub ğŸ¤—ì˜ ë©‹ì§„ ì ì€ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ê³µìœ í•œ ê°•ë ¥í•œ ëª¨ë¸ë“¤ì„ ì•„ì£¼ ì‰½ê²Œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
        "\n",
        "Hubì—ì„œ ì €ì¥ëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ë²•ì€ ë§¤ìš° ê°„ë‹¨í•©ë‹ˆë‹¤:\n",
        "\n",
        "1. https://huggingface.co/models?other=q-learning ì— ì ‘ì†í•´ q-learningìœ¼ë¡œ ì €ì¥ëœ ëª¨ë“  ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.  \n",
        "2. ì›í•˜ëŠ” ëª¨ë¸ì„ ì„ íƒí•˜ê³  `repo_id`ë¥¼ ë³µì‚¬í•©ë‹ˆë‹¤.\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit2/copy-id.png\" alt=\"Copy id\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTth6thRoC6X"
      },
      "source": [
        "3. ê·¸ëŸ° ë‹¤ìŒ `load_from_hub` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” ë‹¤ìŒ ë‘ ê°€ì§€ë¥¼ ì§€ì •í•´ì£¼ë©´ ë©ë‹ˆë‹¤:\n",
        "- `repo_id`: ë³µì‚¬í•œ ì €ì¥ì†Œ ID  \n",
        "- `filename`: í•´ë‹¹ ì €ì¥ì†Œ ì•ˆì— ì €ì¥ëœ ëª¨ë¸ íŒŒì¼ ì´ë¦„"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtrfoTaBoNrd"
      },
      "source": [
        "#### ì´ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Eo8qEzNtCaVI"
      },
      "outputs": [],
      "source": [
        "from urllib.error import HTTPError\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "\n",
        "def load_from_hub(repo_id: str, filename: str) -> str:\n",
        "    \"\"\"\n",
        "    Hugging Face Hubì—ì„œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.\n",
        "    :param repo_id: Hugging Face Hubì—ì„œ ëª¨ë¸ ì €ì¥ì†Œì˜ ID\n",
        "    :param filename: ì €ì¥ì†Œì—ì„œ ëª¨ë¸ zip íŒŒì¼ ì´ë¦„\n",
        "    \"\"\"\n",
        "    # Hubì—ì„œ ëª¨ë¸ì„ ê°€ì ¸ì˜¤ê³ , ë¡œì»¬ ë””ìŠ¤í¬ì— ë‹¤ìš´ë¡œë“œ ë° ìºì‹œí•©ë‹ˆë‹¤\n",
        "    pickle_model = hf_hub_download(\n",
        "        repo_id=repo_id,\n",
        "        filename=filename\n",
        "    )\n",
        "\n",
        "    with open(pickle_model, 'rb') as f:\n",
        "        downloaded_model_file = pickle.load(f)\n",
        "\n",
        "    return downloaded_model_file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_sM2gNioPZH"
      },
      "source": [
        "### ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "JUm9lz2gCQcU"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b58d8892ee24ad4b005fd86f4153474",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "q-learning.pkl:   0%|          | 0.00/24.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'env_id': 'Taxi-v3', 'max_steps': 99, 'n_training_episodes': 25000, 'n_eval_episodes': 100, 'eval_seed': [16, 54, 165, 177, 191, 191, 120, 80, 149, 178, 48, 38, 6, 125, 174, 73, 50, 172, 100, 148, 146, 6, 25, 40, 68, 148, 49, 167, 9, 97, 164, 176, 61, 7, 54, 55, 161, 131, 184, 51, 170, 12, 120, 113, 95, 126, 51, 98, 36, 135, 54, 82, 45, 95, 89, 59, 95, 124, 9, 113, 58, 85, 51, 134, 121, 169, 105, 21, 30, 11, 50, 65, 12, 43, 82, 145, 152, 97, 106, 55, 31, 85, 38, 112, 102, 168, 123, 97, 21, 83, 158, 26, 80, 63, 5, 81, 32, 11, 28, 148], 'learning_rate': 0.7, 'gamma': 0.95, 'epsilon': 1.0, 'max_epsilon': 1.0, 'min_epsilon': 0.05, 'decay_rate': 0.005, 'qtable': array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
            "         0.        ],\n",
            "       [ 2.75200369,  3.94947757,  2.75200369,  3.94947757,  5.20997639,\n",
            "        -5.05052243],\n",
            "       [ 7.93349184,  9.40367562,  7.93349184,  9.40367562, 10.9512375 ,\n",
            "         0.40367562],\n",
            "       ...,\n",
            "       [10.9512375 , 12.58025   , 10.9512375 ,  9.40367562,  1.9512375 ,\n",
            "         1.9512375 ],\n",
            "       [ 5.20997639,  6.53681725,  5.20997639,  6.53681725, -3.79002361,\n",
            "        -3.79002361],\n",
            "       [16.1       , 14.295     , 16.1       , 18.        ,  7.1       ,\n",
            "         7.1       ]])}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "846c7c39ac834f3bbb055387902a5a91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(7.56, 2.706732347314747)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = load_from_hub(repo_id=\"ThomasSimonini/q-Taxi-v3\", filename=\"q-learning.pkl\") # ë‹¤ë¥¸ ëª¨ë¸ì„ ì‚¬ìš©í•´ ë³´ì„¸ìš”\n",
        "\n",
        "print(model)\n",
        "env = gym.make(model[\"env_id\"])\n",
        "\n",
        "evaluate_agent(env, model[\"max_steps\"], model[\"n_eval_episodes\"], model[\"qtable\"], model[\"eval_seed\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "O7pL8rg1MulN"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "caf84f19bd444be5ace49ffe3575ba18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "q-learning.pkl:   0%|          | 0.00/933 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93a81007341c476a8413509e6ff5ae3f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(1.0, 0.0)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = load_from_hub(repo_id=\"ThomasSimonini/q-FrozenLake-v1-no-slippery\", filename=\"q-learning.pkl\") # ë‹¤ë¥¸ ëª¨ë¸ì„ ì‚¬ìš©í•´ ë³´ì„¸ìš”\n",
        "\n",
        "env = gym.make(model[\"env_id\"], is_slippery=False)\n",
        "\n",
        "evaluate_agent(env, model[\"max_steps\"], model[\"n_eval_episodes\"], model[\"qtable\"], model[\"eval_seed\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQAwLnYFPk-s"
      },
      "source": [
        "## ì¶”ê°€ ë„ì „ ê³¼ì œë“¤ ğŸ†\n",
        "\n",
        "**ê°€ì¥ ì¢‹ì€ í•™ìŠµ ë°©ë²•ì€ ì§ì ‘ í•´ë³´ëŠ” ê²ƒ!**  \n",
        "ì§€ê¸ˆê¹Œì§€ ë³¸ ê²ƒì²˜ëŸ¼, í˜„ì¬ì˜ ì—ì´ì „íŠ¸ëŠ” ì•„ì£¼ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ì§€ëŠ” ì•Šì•„ìš”.  \n",
        "ì²« ë²ˆì§¸ ì œì•ˆì€ **í•™ìŠµ íšŸìˆ˜ë¥¼ ëŠ˜ë¦¬ëŠ” ê²ƒ**ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ 1,000,000 ìŠ¤í…ìœ¼ë¡œ í•™ìŠµí•œ ê²°ê³¼ëŠ” ê½¤ ê´œì°®ì•˜ìŠµë‹ˆë‹¤!\n",
        "\n",
        "[ë¦¬ë”ë³´ë“œ](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)ì—ì„œ ë‹¹ì‹ ì˜ ì—ì´ì „íŠ¸ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.  \n",
        "**ì •ìƒì— ì˜¤ë¥¼ ìˆ˜ ìˆì„ê¹Œìš”?**\n",
        "\n",
        "ë¦¬ë”ë³´ë“œ ìˆœìœ„ë¥¼ ì˜¬ë¦¬ê¸° ìœ„í•œ ëª‡ ê°€ì§€ ì•„ì´ë””ì–´:\n",
        "\n",
        "- ë” ë§ì€ ìŠ¤í…ìœ¼ë¡œ í•™ìŠµí•˜ê¸°  \n",
        "- í´ë˜ìŠ¤ë©”ì´íŠ¸ë“¤ì´ ì‚¬ìš©í•œ **í•˜ì´í¼íŒŒë¼ë¯¸í„°**ë¥¼ ì°¸ê³ í•´ ë‹¤ë¥¸ ì„¤ì • ì‹œë„í•´ë³´ê¸°  \n",
        "- **ìƒˆë¡­ê²Œ í•™ìŠµí•œ ëª¨ë¸ì„ Hubì— ì—…ë¡œë“œ**í•˜ê¸° ğŸ”¥  \n",
        "\n",
        "ë¹™íŒ ìœ„ë¥¼ ê±·ê±°ë‚˜ íƒì‹œ ìš´ì „ì´ ë„ˆë¬´ ì§€ë£¨í•˜ë‹¤ë©´?  \n",
        "**í™˜ê²½ì„ ë°”ê¿”ë³´ì„¸ìš”!**  \n",
        "ì˜ˆë¥¼ ë“¤ì–´ `FrozenLake-v1`ì˜ ë¯¸ë„ëŸ¬ìš´(slippery) ë²„ì „ì€ ì–´ë–¤ê°€ìš”?  \n",
        "[Gymnasium ë¬¸ì„œ](https://gymnasium.farama.org/)ë¥¼ ì°¸ê³ í•´ì„œ ì‘ë™ ë°©ì‹ë„ í™•ì¸í•˜ê³ , ì¬ë¯¸ìˆê²Œ ì‹¤í—˜í•´ë³´ì„¸ìš” ğŸ‰"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-fW-EU5WejJ"
      },
      "source": [
        "_____________________________________________________________________\n",
        "\n",
        "ì¶•í•˜í•©ë‹ˆë‹¤ ğŸ¥³ ì²˜ìŒìœ¼ë¡œ ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ë¥¼ ì§ì ‘ êµ¬í˜„í•˜ê³ , í•™ìŠµì‹œí‚¤ê³ , ì—…ë¡œë“œê¹Œì§€ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤!\n",
        "\n",
        "Q-Learningì„ ì´í•´í•˜ëŠ” ê²ƒì€ **ê°€ì¹˜ ê¸°ë°˜(value-based) ë°©ë²•ë¡ ì„ ì´í•´í•˜ëŠ” ë° ìˆì–´ ë§¤ìš° ì¤‘ìš”í•œ ë‹¨ê³„**ì…ë‹ˆë‹¤.\n",
        "\n",
        "ë‹¤ìŒ ìœ ë‹›ì—ì„œëŠ” Deep Q-Learningì„ ë‹¤ë£¨ê²Œ ë©ë‹ˆë‹¤.  \n",
        "Q-í…Œì´ë¸”ì„ ë§Œë“¤ê³  ì—…ë°ì´íŠ¸í•˜ëŠ” ë°©ì‹ì€ ì¢‹ì€ ì „ëµì´ì§€ë§Œ â€” **í™•ì¥ì„±ì´ ë–¨ì–´ì§„ë‹¤ëŠ” ë‹¨ì ì´ ìˆìŠµë‹ˆë‹¤.**\n",
        "\n",
        "ì˜ˆë¥¼ ë“¤ì–´, Doom ê²Œì„ì„ í•™ìŠµí•˜ëŠ” ì—ì´ì „íŠ¸ë¥¼ ë§Œë“ ë‹¤ê³  ìƒìƒí•´ë³´ì„¸ìš”.\n",
        "\n",
        "<img src=\"https://vizdoom.cs.put.edu.pl/user/pages/01.tutorial/basic.png\" alt=\"Doom\"/>\n",
        "\n",
        "Doom ê°™ì€ í™˜ê²½ì€ ìƒíƒœ ê³µê°„ì´ ë§¤ìš° í¬ê³ , ìˆ˜ë°±ë§Œ ê°œì˜ ìƒíƒœê°€ ì¡´ì¬í•©ë‹ˆë‹¤.  \n",
        "ì´ëŸ° í™˜ê²½ì—ì„œëŠ” Q-í…Œì´ë¸”ì„ ìƒì„±í•˜ê³  ìœ ì§€í•˜ëŠ” ê²ƒì´ ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤.\n",
        "\n",
        "ê·¸ë˜ì„œ ë‹¤ìŒ ìœ ë‹›ì—ì„œëŠ” Deep Q-Learningì„ ë°°ì›ë‹ˆë‹¤.  \n",
        "Deep Q-Learningì€ **ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ì—¬, ì£¼ì–´ì§„ ìƒíƒœì—ì„œ ê°€ëŠ¥í•œ í–‰ë™ë“¤ ê°ê°ì˜ Qê°’ì„ ê·¼ì‚¬**í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/atari-envs.gif\" alt=\"Environments\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjLhT70TEZIn"
      },
      "source": [
        "Unit 3ì—ì„œ ë§Œë‚˜ìš”! ğŸ”¥  \n",
        "\n",
        "## ê³„ì† ë°°ìš°ê³ , ë©‹ì§€ê²Œ ë‚˜ì•„ê°€ìš” ğŸ¤—"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "67OdoKL63eDD",
        "B2_-8b8z5k54",
        "8R5ej1fS4P2V",
        "Pnpk2ePoem3r"
      ],
      "include_colab_link": true,
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "learn2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
