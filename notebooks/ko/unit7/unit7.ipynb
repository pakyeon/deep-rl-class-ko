{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aa47b12",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/pakyeon/deep-rl-class-ko/blob/main/notebooks/ko/unit7/unit7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a806440",
   "metadata": {},
   "source": [
    "# 유닛 7: 다중 에이전트 및 AI vs. AI 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cde755a",
   "metadata": {},
   "source": [
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit0/thumbnail.png\" alt=\"Thumbnail\"/>\n",
    "\n",
    "이 노트북에서는 다중 에이전트 시스템을 훈련시킬 것입니다. 훈련 시킬 에이전트는 **상대 팀을 이겨야 하는 2대2 축구 팀입니다.**\n",
    "\n",
    "그리고 여러분은 AI vs. AI 챌린지에 참여하게 되는데, 훈련된 여러분의 에이전트가 **매일 다른 반 친구들의 에이전트와 경쟁하고 새로운 리더보드에 순위를 매기게 됩니다.**\n",
    "\n",
    "인증 절차를 위해 이 실습을 검증하려면 훈련된 모델을 푸시하기만 하면 됩니다. **검증을 위해 달성해야 하는 최소 결과는 없습니다.**\n",
    "\n",
    "인증 프로세스에 대한 자세한 내용은 이 섹션을 확인하세요 👉 https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e70a790",
   "metadata": {},
   "source": [
    "⬇️ **이 유닛을 마치면 여러분이 달성하게 될 예시입니다.** ⬇️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9e7159",
   "metadata": {},
   "source": [
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit10/soccertwos.gif\" alt=\"SoccerTwos\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeffaec2",
   "metadata": {},
   "source": [
    "### 🎮 환경:\n",
    "\n",
    "- [2대2 축구](https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Learning-Environment-Examples.md#soccer-twos)\n",
    "\n",
    "### 📚 강화학습 라이브러리:\n",
    "\n",
    "- [ML-Agents](https://github.com/Unity-Technologies/ml-agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6206fe",
   "metadata": {},
   "source": [
    "튜토리얼을 지속적으로 개선하고 있으니, **이 노트북에서 문제가 발견되면** [GitHub 저장소에 이슈를 등록해주세요](https://github.com/huggingface/deep-rl-class/issues)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6467a75",
   "metadata": {},
   "source": [
    "## 이 노트북의 목표 🏆\n",
    "\n",
    "노트북을 완료하면 다음을 할 수 있습니다:\n",
    "\n",
    "- 환경 라이브러리인 **ML-Agents의 작동 방식**을 이해합니다.  \n",
    "- **Unity 환경에서 에이전트를 훈련시키는 방법**을 익힙니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f5d466",
   "metadata": {},
   "source": [
    "## 이 노트북은 딥 강화학습 과정의 일부입니다  \n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/deep-rl-course-illustration.jpg\" alt=\"Deep RL Course illustration\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d630e100",
   "metadata": {},
   "source": [
    "이 무료 강의에서는 다음을 배울 수 있습니다:\n",
    "\n",
    "- 📖 **이론과 실습**을 통해 딥 강화학습(Deep Reinforcement Learning)을 학습합니다.  \n",
    "- 🧑‍💻 Stable Baselines3, RL Baselines3 Zoo, CleanRL, Sample Factory 2.0 같은 **유명한 Deep RL 라이브러리 사용법**을 익힙니다.  \n",
    "- 🤖 **다양한 환경에서 에이전트를 학습**시켜 봅니다.  \n",
    "\n",
    "그리고 더 많은 내용을 원한다면 📚 **전체 커리큘럼은 여기서 확인하세요** 👉 https://simoninithomas.github.io/deep-rl-course\n",
    "\n",
    "또한, 매 유닛이 공개될 때마다 링크와 도전 과제, 업데이트 내용을 받아보려면  \n",
    "**[수강 신청](http://eepurl.com/ic5ZUD)** 을 꼭 해주세요!  \n",
    "(이메일을 통해 정보를 보내드리기 위함입니다.)\n",
    "\n",
    "커뮤니티 및 강사진과의 교류를 원한다면  \n",
    "**디스코드 서버에 참여하세요** 👉🏻 https://discord.gg/ydHrjt3WP5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a70b5a8",
   "metadata": {},
   "source": [
    "## 사전 준비 사항 🏗️  \n",
    "노트북을 시작하기 전에 다음을 완료해야 합니다:\n",
    "\n",
    "🔲 📚 **[유닛 5를 읽고 ML-Agents가 무엇이며 어떻게 작동하는지 학습하세요](https://huggingface.co/deep-rl-course/unit5/introduction)** 🤗"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3699cc40",
   "metadata": {},
   "source": [
    "# 에이전트를 훈련시켜 봅시다 🚀\n",
    "\n",
    "**자격증 과정을 위한 실습 인증을 받으려면, 훈련된 모델을 Hugging Face Hub에 업로드하기만 하면 됩니다.**  \n",
    "이 유닛에서는 특정 성과를 달성하지 않아도 인증이 가능합니다.  \n",
    "하지만 좋은 성과를 내고 싶다면 다음을 목표로 해보세요:\n",
    "\n",
    "- `Pyramids` : 평균 보상 = 1.75  \n",
    "- `SnowballTarget` : 평균 보상 = 15 또는 에피소드당 30개의 표적 명중"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be4ad6",
   "metadata": {},
   "source": [
    "## GPU 설정하기 💪  \n",
    "- **에이전트의 훈련을 가속하기 위해 GPU를 사용할 예정입니다**. 이를 위해 `런타임 > 런타임 유형 변경`으로 이동하세요.\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step1.jpg\" alt=\"GPU Step 1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f72bbf",
   "metadata": {},
   "source": [
    "- `하드웨어 가속기 > GPU`\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step2.jpg\" alt=\"GPU Step 2\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f9e560",
   "metadata": {},
   "source": [
    "## 리포지토리 클론하기 🔽\n",
    "\n",
    "- **ML-Agents**가 포함된 리포지토리를 클론해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5131c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# 저장소 복제(3분 소요)\n",
    "!git clone --depth 1 https://github.com/Unity-Technologies/ml-agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c4d623",
   "metadata": {},
   "source": [
    "## 가상 환경 설정하기 🔽  \n",
    "- **ML-Agents**가 Colab에서 정상적으로 실행되기 위해서는, Colab의 Python 버전이 해당 라이브러리의 Python 요구 사항을 충족해야 합니다.\n",
    "\n",
    "- 지원되는 Python 버전은 `setup.py` 파일의 `python_requires` 항목에서 확인할 수 있습니다. 이 파일들은 **ML-Agents** 라이브러리를 사용할 수 있도록 설정하는 데 필요하며, 다음 위치에 있습니다:  \n",
    "  - `/content/ml-agents/ml-agents/setup.py`  \n",
    "  - `/content/ml-agents/ml-agents-envs/setup.py`\n",
    "\n",
    "- 현재 Colab의 Python 버전(`!python --version`으로 확인 가능)은 라이브러리의 `python_requires` 요구 사항과 일치하지 않기 때문에, 설치가 조용히 실패하고 나중에 아래와 같은 오류가 발생할 수 있습니다:  \n",
    "  - `/bin/bash: line 1: mlagents-learn: command not found`  \n",
    "  - `/bin/bash: line 1: mlagents-push-to-hf: command not found`\n",
    "\n",
    "- 이를 해결하기 위해, **ML-Agents** 라이브러리와 호환되는 Python 버전으로 가상 환경을 생성합니다.\n",
    "\n",
    "`참고:` *향후 호환성을 위해, 항상 설치 파일의 `python_requires` 항목을 확인하고, Colab의 Python 버전이 맞지 않을 경우 아래 스크립트에서 설정된 최대 지원 Python 버전으로 가상 환경을 구성하세요.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf39ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab의 현재 Python 버전 (ML-Agents와 호환되지 않음)\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756961ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# virtualenv 설치 및 가상 환경 생성\n",
    "!pip install virtualenv\n",
    "!virtualenv myenv\n",
    "\n",
    "# Miniconda 다운로드 및 설치\n",
    "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
    "!./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
    "\n",
    "# Miniconda 활성화 후 Python 3.10.12 버전 설치\n",
    "!source /usr/local/bin/activate\n",
    "!conda install -q -y --prefix /usr/local python=3.10.12 ujson  # 여기서 버전 명시\n",
    "\n",
    "# Python 및 conda 경로에 대한 환경 변수 설정\n",
    "!export PYTHONPATH=/usr/local/lib/python3.10/site-packages/\n",
    "!export CONDA_PREFIX=/usr/local/envs/myenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac444f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 가상 환경의 Python 버전 (ML-Agents와 호환됨)\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee35361",
   "metadata": {},
   "source": [
    "## 의존성 설치하기 🔽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e4b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# 리포지토리 내부로 이동하여 패키지 설치 (약 3분 소요)\n",
    "%cd ml-agents\n",
    "!pip3 install -e ./ml-agents-envs\n",
    "!pip3 install -e ./ml-agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ebe41a",
   "metadata": {},
   "source": [
    "## SnowballTarget ⛄\n",
    "\n",
    "이 환경이 어떻게 동작하는지 다시 확인하고 싶다면 아래 링크를 참고하세요 👉  \n",
    "https://huggingface.co/deep-rl-course/unit5/snowball-target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f31557",
   "metadata": {},
   "source": [
    "### 환경 zip 파일을 `./training-envs-executables/linux/` 경로로 다운로드 및 이동  \n",
    "- 환경 실행 파일은 zip 파일로 제공됨  \n",
    "- 해당 파일을 다운로드하여 `./training-envs-executables/linux/` 경로에 배치해야 함  \n",
    "- Colab을 사용하므로, OS가 Ubuntu(Linux)이기 때문에 Linux 실행 파일을 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b67895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에서 training-envs-executables 및 linux 디렉토리를 생성함\n",
    "!mkdir ./training-envs-executables\n",
    "!mkdir ./training-envs-executables/linux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f796a4ec",
   "metadata": {},
   "source": [
    "`wget`을 사용하여 https://github.com/huggingface/Snowball-Target 에서 SnowballTarget.zip 파일을 다운로드함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec188e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://github.com/huggingface/Snowball-Target/raw/main/SnowballTarget.zip\" -O ./training-envs-executables/linux/SnowballTarget.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0156fc",
   "metadata": {},
   "source": [
    "실행 파일인 executable.zip을 압축 해제함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828dab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!unzip -d ./training-envs-executables/linux/ ./training-envs-executables/linux/SnowballTarget.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9b34de",
   "metadata": {},
   "source": [
    "파일에 접근할 수 있는지 확인함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc664b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod -R 755 ./training-envs-executables/linux/SnowballTarget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8300eb",
   "metadata": {},
   "source": [
    "### SnowballTarget 설정 파일 정의  \n",
    "- ML-Agents에서는 **훈련 하이퍼파라미터를 config.yaml 파일에 정의**함  \n",
    "\n",
    "여러 하이퍼파라미터가 존재하며, 자세한 설명은 [공식 문서](https://github.com/Unity-Technologies/ml-agents/blob/release_20_docs/docs/Training-Configuration-File.md)를 참고할 것  \n",
    "\n",
    "따라서 `./content/ml-agents/config/ppo/` 경로에 `SnowballTarget.yaml` 설정 파일을 생성해야 함  \n",
    "\n",
    "아래는 `SnowballTarget.yaml`에 복사해 넣을 수 있는 초기 버전이며, **수정이 필요함**\n",
    "\n",
    "```\n",
    "behaviors:\n",
    "  SnowballTarget:\n",
    "    trainer_type: ppo\n",
    "    summary_freq: 10000\n",
    "    keep_checkpoints: 10\n",
    "    checkpoint_interval: 50000\n",
    "    max_steps: 200000\n",
    "    time_horizon: 64\n",
    "    threaded: false\n",
    "    hyperparameters:\n",
    "      learning_rate: 0.0003\n",
    "      learning_rate_schedule: linear\n",
    "      batch_size: 128\n",
    "      buffer_size: 2048\n",
    "      beta: 0.005\n",
    "      epsilon: 0.2\n",
    "      lambd: 0.95\n",
    "      num_epoch: 3\n",
    "    network_settings:\n",
    "      normalize: false\n",
    "      hidden_units: 256\n",
    "      num_layers: 2\n",
    "      vis_encode_type: simple\n",
    "    reward_signals:\n",
    "      extrinsic:\n",
    "        gamma: 0.99\n",
    "        strength: 1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea9476f",
   "metadata": {},
   "source": [
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballfight_config1.png\" alt=\"Config SnowballTarget\"/>\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballfight_config2.png\" alt=\"Config SnowballTarget\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c897b379",
   "metadata": {},
   "source": [
    "실험을 위해 일부 하이퍼파라미터를 **수정해보는 것도 추천됨**. 각 하이퍼파라미터에 대한 자세한 설명은 Unity의 [공식 문서](https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Training-Configuration-File.md)에서 확인 가능함.\n",
    "\n",
    "이제 설정 파일을 만들고 대부분의 하이퍼파라미터에 대한 이해도 되었으므로, **에이전트 훈련을 시작할 준비가 완료됨 🔥**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cf3fe0",
   "metadata": {},
   "source": [
    "### 에이전트 훈련  \n",
    "\n",
    "에이전트를 훈련시키기 위해서는 **`mlagents-learn` 명령어를 실행하고 환경 실행 파일을 지정**하면 됨  \n",
    "\n",
    "다음 네 가지 파라미터를 정의함:  \n",
    "\n",
    "1. `mlagents-learn <config>`: 하이퍼파라미터 설정 파일 경로  \n",
    "2. `--env`: 환경 실행 파일 경로  \n",
    "3. `--run_id`: 훈련 실행에 부여할 이름  \n",
    "4. `--no-graphics`: 훈련 중 시각화를 비활성화  \n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/mlagentslearn.png\" alt=\"MlAgents learn\"/>\n",
    "\n",
    "모델을 훈련시킬 때, 중단된 훈련을 이어서 하려면 `--resume` 플래그를 사용함  \n",
    "\n",
    "> `--resume` 사용 시 첫 실행은 실패할 수 있음. 에러가 발생하면 블록을 다시 실행하면 해결됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bfe002",
   "metadata": {},
   "source": [
    "훈련은 구성에 따라 **약 10~35분** 소요될 수 있음.  \n",
    "☕️ 잠시 쉬고 와도 좋음. 당신은 그럴 자격이 있어요 🤗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49078326",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-learn ./config/ppo/SnowballTarget.yaml --env=./training-envs-executables/linux/SnowballTarget/SnowballTarget --run-id=\"SnowballTarget1\" --no-graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239a5237",
   "metadata": {},
   "source": [
    "### 에이전트를 🤗 Hub에 푸시하기\n",
    "\n",
    "- 이제 에이전트를 훈련했으니, **브라우저에서 플레이하는 것을 시각화할 수 있도록 Hub에 푸시할 준비가 되었습니다🔥.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8201f5",
   "metadata": {},
   "source": [
    "모델을 커뮤니티와 공유하려면 다음 세 단계를 더 따라야 합니다.\n",
    "\n",
    "1️⃣ (아직 하지 않았다면) HF 계정 생성 ➡ [https://huggingface.co/join](https://huggingface.co/join)\n",
    "\n",
    "2️⃣ 로그인한 후, Hugging Face 웹사이트에서 인증 토큰을 저장해야 합니다.\n",
    "- 새 토큰 생성 ([https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)) **쓰기 역할 포함**\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg\" alt=\"Create HF Token\">\n",
    "\n",
    "- 토큰 복사\n",
    "- 아래 셀을 실행하고 토큰 붙여넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e148ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689a82b6",
   "metadata": {},
   "source": [
    "Google Colab이나 Jupyter Notebook을 사용하지 않는 경우, 아래 명령어를 대신 사용해야 합니다: `huggingface-cli login`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77762b5",
   "metadata": {},
   "source": [
    "그런 다음 간단히 `mlagents-push-to-hf`를 실행하면 됩니다.\n",
    "\n",
    "그리고 4가지 매개변수를 정의합니다:\n",
    "\n",
    "1.  `--run-id`: 훈련 실행 ID의 이름입니다.\n",
    "2.  `--local-dir`: 에이전트가 저장된 위치로, results/\\<run\\_id 이름\\>입니다. 따라서 제 경우에는 results/First Training입니다.\n",
    "3.  `--repo-id`: 생성하거나 업데이트하려는 Hugging Face 저장소 이름입니다. 항상 \\<여러분의 huggingface 사용자 이름\\>/\\<저장소 이름\\> 형식입니다.\n",
    "    저장소가 존재하지 않으면 **자동으로 생성됩니다**\n",
    "4.  `--commit-message`: HF 저장소는 Git 저장소이므로 커밋 메시지를 정의해야 합니다.\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/mlagentspushtohub.png\" alt=\"Push to Hub\"/>\n",
    "\n",
    "예시:\n",
    "\n",
    "`!mlagents-push-to-hf  --run-id=\"SnowballTarget1\" --local-dir=\"./results/SnowballTarget1\" --repo-id=\"ThomasSimonini/ppo-SnowballTarget\"  --commit-message=\"First Push\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74050a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-push-to-hf --run-id=\"SnowballTarget1\" --local-dir=\"./results/SnowballTarget1\" --repo-id=\"ThomasSimonini/ppo-SnowballTarget\" --commit-message=\"First Push\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee4691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-push-to-hf  --run-id= # 실행 ID 추가  --local-dir= # 로컬 디렉토리  --repo-id= # 저장소 ID  --commit-message= # 커밋 메시지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bbfac1",
   "metadata": {},
   "source": [
    "그렇지 않고 모든 것이 제대로 작동했다면 프로세스 끝에 다음과 같은 내용이 표시될 것입니다(URL은 다르겠지만 😆):\n",
    "\n",
    "```\n",
    "Your model is pushed to the hub. You can view your model here: https://huggingface.co/ThomasSimonini/ppo-SnowballTarget\n",
    "```\n",
    "\n",
    "이것은 여러분의 모델 링크이며, 사용 방법을 설명하는 모델 카드, Tensorboard 및 설정 파일이 포함되어 있습니다. **멋진 점은 이것이 Git 저장소라는 것입니다. 즉, 다른 커밋을 가질 수 있고, 새로운 푸시로 저장소를 업데이트하는 등을 할 수 있습니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eec90f8",
   "metadata": {},
   "source": [
    "하지만 이제 가장 좋은 점이 나옵니다: **온라인에서 에이전트를 시각화할 수 있다는 것 👀.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aa6407",
   "metadata": {},
   "source": [
    "### 에이전트 플레이 시청하기 👀\n",
    "\n",
    "이 단계는 간단합니다:\n",
    "\n",
    "1. 여기로 이동합니다: https://huggingface.co/spaces/ThomasSimonini/ML-Agents-SnowballTarget\n",
    "\n",
    "2. 게임을 실행하고 오른쪽 하단 버튼을 클릭하여 전체 화면으로 만듭니다\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballtarget_load.png\" alt=\"Snowballtarget load\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbdf421",
   "metadata": {},
   "source": [
    "1. 1단계에서 사용자 이름(사용자 이름은 대소문자를 구분합니다. 예를 들어 제 사용자 이름은 ThomasSimonini이지 thomassimonini 또는 ThOmasImoNInI가 아닙니다)을 입력하고 검색 버튼을 클릭합니다.\n",
    "\n",
    "2. 2단계에서 모델 저장소를 선택합니다.\n",
    "\n",
    "3. 3단계에서 **다시 플레이할 모델을 선택합니다**:\n",
    "  - 500000 타임스텝마다 모델을 저장했기 때문에 여러 개가 있습니다.\n",
    "  - 하지만 최신 모델을 원하므로 `SnowballTarget.onnx`를 선택합니다.\n",
    "\n",
    "👉 **다양한 모델 스텝으로 시도하여 에이전트의 개선 사항을 보는 것**이 좋습니다.\n",
    "\n",
    "그리고 Discord의 #rl-i-made-this 채널에 에이전트가 얻은 최고 점수를 마음껏 공유해주세요 🔥\n",
    "\n",
    "이제 Pyramids라고 불리는 더 어려운 환경을 시도해 봅시다..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5365d4ff",
   "metadata": {},
   "source": [
    "## 피라미드 🏆\n",
    "\n",
    "### 환경 zip 파일을 `./training-envs-executables/linux/`로 다운로드 및 이동\n",
    "- 우리의 환경 실행 파일은 zip 파일 안에 있습니다.\n",
    "- 이 파일을 다운로드하여 `./training-envs-executables/linux/`에 놓아야 합니다.\n",
    "- Colab을 사용하기 때문에 Linux 실행 파일을 사용합니다. Colab 머신의 OS는 Ubuntu(Linux)이기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338e2040",
   "metadata": {},
   "source": [
    "`wget`을 사용하여 [https://www.google.com/search?q=https://huggingface.co/spaces/unity/ML-Agents-Pyramids/resolve/main/Pyramids.zip%EC%97%90%EC%84%9C](https://www.google.com/search?q=https://huggingface.co/spaces/unity/ML-Agents-Pyramids/resolve/main/Pyramids.zip%EC%97%90%EC%84%9C) Pyramids.zip 파일을 다운로드했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d31465",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://huggingface.co/spaces/unity/ML-Agents-Pyramids/resolve/main/Pyramids.zip\" -O ./training-envs-executables/linux/Pyramids.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564af112",
   "metadata": {},
   "source": [
    "실행 파일 zip 파일의 압축을 풉니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a727297",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!unzip -d ./training-envs-executables/linux/ ./training-envs-executables/linux/Pyramids.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd8ed0d",
   "metadata": {},
   "source": [
    "파일에 접근 가능한지 확인하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e655ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod -R 755 ./training-envs-executables/linux/Pyramids/Pyramids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad56cfd8",
   "metadata": {},
   "source": [
    "### PyramidsRND 설정 파일 수정하기\n",
    "- 사용자 지정 환경이었던 첫 번째 환경과 달리, **피라미드는 Unity 팀이 만들었습니다**.\n",
    "- 따라서 PyramidsRND 설정 파일은 이미 존재하며 ./content/ml-agents/config/ppo/PyramidsRND.yaml에 있습니다.\n",
    "- PyramidsRND의 \"RND\"가 왜 붙었는지 궁금해하실 수 있습니다. RND는 *random network distillation*의 약자로, 호기심 보상을 생성하는 한 가지 방법입니다. 이에 대해 더 자세히 알고 싶다면 이 기술을 설명하는 글을 작성했습니다: https://medium.com/data-from-the-trenches/curiosity-driven-learning-through-random-network-distillation-488ffd8e5938\n",
    "\n",
    "이 훈련을 위해 한 가지를 수정할 것입니다:\n",
    "- 전체 훈련 스텝 하이퍼파라미터는 너무 높습니다. 100만 훈련 스텝만으로도 벤치마크(평균 보상 = 1.75)에 도달할 수 있기 때문입니다.\n",
    "👉 이를 위해 config/ppo/PyramidsRND.yaml로 이동하여 **이것들을 max_steps 1000000으로 수정합니다.**\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/pyramids-config.png\" alt=\"Pyramids config\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a87b86",
   "metadata": {},
   "source": [
    "실험 삼아 다른 하이퍼파라미터도 수정해 보세요. Unity는 [각 하이퍼파라미터를 설명하는 아주 좋은 문서를 여기에서 제공합니다](https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Training-Configuration-File.md).\n",
    "\n",
    "이제 에이전트를 훈련할 준비가 되었습니다 🔥."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff95810f",
   "metadata": {},
   "source": [
    "### 에이전트 훈련하기\n",
    "\n",
    "훈련은 머신에 따라 30분에서 45분 정도 소요될 것입니다. ☕️ 한 잔 하세요. 그럴 자격이 있습니다 🤗."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6830052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-learn ./config/ppo/PyramidsRND.yaml --env=./training-envs-executables/linux/Pyramids/Pyramids --run-id=\"Pyramids Training\" --no-graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbe5a80",
   "metadata": {},
   "source": [
    "### 에이전트를 🤗 Hub에 푸시하기\n",
    "\n",
    "- 이제 에이전트를 훈련했으니, **브라우저에서 플레이하는 것을 시각화할 수 있도록 Hub에 푸시할 준비가 되었습니다🔥.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77909a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-push-to-hf  --run-id= # 실행 ID 추가  --local-dir= # 로컬 디렉토리  --repo-id= # 저장소 ID  --commit-message= # 커밋 메시지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2156f2",
   "metadata": {},
   "source": [
    "### 에이전트 플레이 시청하기 👀\n",
    "\n",
    "👉 https://huggingface.co/spaces/unity/ML-Agents-Pyramids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a1dd18",
   "metadata": {},
   "source": [
    "### 🎁 보너스: 다른 환경에서 훈련해 보는 건 어떠세요?\n",
    "이제 MLAgents를 사용하여 에이전트를 훈련하는 방법을 알게 되었으니, **다른 환경에서 시도해 보는 건 어떨까요?**\n",
    "\n",
    "MLAgents는 17가지의 다양한 환경을 제공하며, 저희는 몇 가지 사용자 지정 환경을 구축하고 있습니다. 배우는 가장 좋은 방법은 직접 시도해보는 것입니다. 즐거운 시간 보내세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c034241c",
   "metadata": {},
   "source": [
    "![cover](https://miro.medium.com/max/1400/0*xERdThTRRM2k_U9f.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b42d4",
   "metadata": {},
   "source": [
    "Unity 공식 환경 전체 목록은 여기에서 확인할 수 있습니다 👉 https://github.com/Unity-Technologies/ml-agents/blob/develop/docs/Learning-Environment-Examples.md\n",
    "\n",
    "에이전트를 시각화할 수 있는 데모는 여기 있습니다 👉 https://huggingface.co/unity\n",
    "\n",
    "현재 통합된 환경은 다음과 같습니다:\n",
    "- [Worm](https://huggingface.co/spaces/unity/ML-Agents-Worm) 데모: **벌레가 기어가도록** 가르칩니다.\n",
    "- [Walker](https://huggingface.co/spaces/unity/ML-Agents-Walker) 데모: 에이전트에게 **목표를 향해 걷도록** 가르칩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7787d2e6",
   "metadata": {},
   "source": [
    "오늘 할 내용은 여기까지입니다. 이 튜토리얼을 마치신 것을 축하드립니다!\n",
    "\n",
    "배우는 가장 좋은 방법은 연습하고 시도해보는 것입니다. 다른 환경에서 시도해 보는 건 어떨까요? ML-Agents에는 17가지의 다른 환경이 있지만, 여러분만의 환경을 만들 수도 있습니다. 문서를 확인하고 즐거운 시간 보내세요!\n",
    "\n",
    "Unit 6에서 만나요 🔥,\n",
    "\n",
    "## 계속 배우고, 멋지게 지내세요 🤗"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
